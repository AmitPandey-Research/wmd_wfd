{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a72e80a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------------------] 1.4% 23.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=-------------------------------------------------] 3.4% 56.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==------------------------------------------------] 5.4% 89.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===-----------------------------------------------] 7.3% 122.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====----------------------------------------------] 9.4% 156.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====---------------------------------------------] 11.4% 189.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======--------------------------------------------] 13.5% 223.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======-------------------------------------------] 15.5% 257.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========------------------------------------------] 17.6% 293.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========----------------------------------------] 20.6% 342.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========---------------------------------------] 23.5% 390.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============--------------------------------------] 25.6% 425.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============-------------------------------------] 27.6% 459.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============-----------------------------------] 30.8% 511.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================----------------------------------] 32.8% 544.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================---------------------------------] 34.9% 579.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================--------------------------------] 37.0% 614.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================-------------------------------] 38.9% 647.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====================-----------------------------] 43.0% 715.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================---------------------------] 46.3% 769.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================--------------------------] 48.6% 807.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================------------------------] 52.8% 877.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========================-----------------------] 54.9% 913.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================----------------------] 57.0% 947.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================--------------------] 61.1% 1015.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================================------------------] 64.8% 1077.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================-----------------] 67.7% 1125.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================================---------------] 70.6% 1173.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================================--------------] 72.5% 1205.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====================================-------------] 74.5% 1238.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================================-----------] 78.7% 1307.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================================---------] 82.2% 1366.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================================--------] 84.4% 1402.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================================------] 88.5% 1471.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================================----] 92.5% 1538.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============================================---] 95.6% 1589.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================-] 99.8% 1659.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "import gensim\n",
    "w2v_emb = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d042d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home2/dhawals1939/Amit Pandey/wmd_lite/src'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "666a8319",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../GoogleNews-vectors-negative300.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37299/2431599767.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m w = models.KeyedVectors.load_word2vec_format(\n\u001b[0m\u001b[1;32m      4\u001b[0m     '../GoogleNews-vectors-negative300.bin', binary=True)\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \"\"\"\n\u001b[0;32m-> 1629\u001b[0;31m         return _load_word2vec_format(\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m             \u001b[0;31m# deduce both vocab_size & vector_size from 1st pass over file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     fobj = _shortcut_open(\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../GoogleNews-vectors-negative300.bin'"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "w = models.KeyedVectors.load_word2vec_format(\n",
    "    '../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17dac685",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37299/519734542.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'obama'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'w' is not defined"
     ]
    }
   ],
   "source": [
    "w['obama']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "946ec828",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_emb = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b31ab5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append(\"../../../Amit Pandey/nltk_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea94347a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = list(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a67dd3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 1: Imports done\n",
      "\n",
      "check 2 : function definitions \n",
      "\n",
      " loading train and test dataset\n",
      "\n",
      "check 3 : dataset loaded \n",
      "\n",
      " No of test docs and labels loaded: 222   222 \n",
      "\n",
      " No of train docs and labels loaded: 514   514 \n",
      "\n",
      " Model initialization started wtih NORMAL WMD with MIN cost and glove vectors  \n",
      "\n",
      " check 4: model initialization successful \n",
      "\n",
      "\n",
      "running test9 \n",
      "running test14 \n",
      "running test15 \n",
      "running test17 \n",
      "running test3 \n",
      "running test16 \n",
      "running test10 \n",
      "running test8 \n",
      "running test0 \n",
      "running test12 \n",
      "running test4 \n",
      "running test1 \n",
      "running test2 \n",
      "running test13 \n",
      "running test11 \n",
      "running test5 \n",
      "running test18 \n",
      "running test19 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "running test6 \n",
      "\n",
      "running test7 \n",
      "\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 13  ['football']\n",
      "pred 7 for test 13  ['football']\n",
      "pred 11 for test 13  ['football']\n",
      "pred 15 for test 13  ['football']\n",
      "pred 21 for test 13  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 15  ['football']\n",
      "pred 7 for test 15  ['football']\n",
      "pred 11 for test 15  ['football']\n",
      "pred 15 for test 15  ['football']\n",
      "pred 21 for test 15  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 10  ['football']\n",
      "pred 7 for test 10  ['football']\n",
      "pred 11 for test 10  ['football']\n",
      "pred 15 for test 10  ['football']\n",
      "pred 21 for test 10  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 9  ['football']\n",
      "pred 7 for test 9  ['football']\n",
      "pred 11 for test 9  ['football']\n",
      "pred 15 for test 9  ['football']\n",
      "pred 21 for test 9  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 8  ['football']\n",
      "pred 7 for test 8  ['football']\n",
      "pred 11 for test 8  ['football']\n",
      "pred 15 for test 8  ['football']\n",
      "pred 21 for test 8  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 2  ['football']\n",
      "pred 7 for test 2  ['football']\n",
      "pred 11 for test 2  ['football']\n",
      "pred 15 for test 2  ['football']\n",
      "Starting distance calculation############################### \n",
      "pred 21 for test 2  \n",
      "pred 5 for test 6  ['football']\n",
      "pred 7 for test 6  ['football']\n",
      "pred 11 for test 6  ['football']\n",
      "pred 15 for test 6  ['football']\n",
      "pred 21 for test 6  ['football']\n",
      "['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 18  ['football']\n",
      "pred 7 for test 18  ['football']\n",
      "pred 11 for test 18  ['football']\n",
      "pred 15 for test 18  ['football']\n",
      "pred 21 for test 18  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 4  ['football']\n",
      "pred 7 for test 4  ['football']\n",
      "pred 11 for test 4  ['football']\n",
      "pred 15 for test 4  ['football']\n",
      "pred 21 for test 4  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 12  ['football']\n",
      "pred 7 for test 12  ['football']\n",
      "pred 11 for test 12  ['football']\n",
      "pred 15 for test 12  ['football']\n",
      "pred 21 for test 12  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 0  ['football']\n",
      "pred 7 for test 0  ['football']\n",
      "pred 11 for test 0  ['football']\n",
      "pred 15 for test 0  ['football']\n",
      "pred 21 for test 0  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 1  ['football']\n",
      "pred 7 for test 1  ['football']\n",
      "pred 11 for test 1  ['football']\n",
      "pred 15 for test 1  ['football']\n",
      "pred 21 for test 1  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 17  ['football']\n",
      "pred 7 for test 17  ['football']\n",
      "pred 11 for test 17  ['football']\n",
      "pred 15 for test 17  ['football']\n",
      "pred 21 for test 17  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 3  ['football']\n",
      "pred 7 for test 3  ['football']\n",
      "pred 11 for test 3  ['football']\n",
      "pred 15 for test 3  ['football']\n",
      "pred 21 for test 3  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 11  ['football']\n",
      "pred 7 for test 11  ['football']\n",
      "pred 11 for test 11  ['football']\n",
      "pred 15 for test 11  ['football']\n",
      "pred 21 for test 11  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 5  ['football']\n",
      "pred 7 for test 5  ['football']\n",
      "pred 11 for test 5  ['football']\n",
      "pred 15 for test 5  ['football']\n",
      "pred 21 for test 5  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 16  ['football']\n",
      "pred 7 for test 16  ['football']\n",
      "pred 11 for test 16  ['football']\n",
      "pred 15 for test 16  ['football']\n",
      "pred 21 for test 16  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 7  ['football']\n",
      "pred 7 for test 7  ['football']\n",
      "pred 11 for test 7  ['football']\n",
      "pred 15 for test 7  ['football']\n",
      "pred 21 for test 7  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 14  ['football']\n",
      "pred 7 for test 14  ['football']\n",
      "pred 11 for test 14  ['football']\n",
      "pred 15 for test 14  ['football']\n",
      "pred 21 for test 14  ['football']\n",
      "Starting distance calculation############################### \n",
      "\n",
      "pred 5 for test 19  ['football']\n",
      "pred 7 for test 19  ['football']\n",
      "pred 11 for test 19  ['football']\n",
      "pred 15 for test 19  ['football']\n",
      "pred 21 for test 19  ['football']\n",
      "\n",
      " time taken:  147.61259865760803\n",
      "..................\n",
      "\n",
      "\n",
      "\n",
      "[{0: ['cricket', [1, 2, 0], ['cricket', 'football', 'football'], [6.4483796278225745, 6.83206604978979, 6.947852794854834], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {1: ['tennis', [1, 2, 0], ['cricket', 'football', 'football'], [6.397477020845434, 6.607054366961158, 6.916004403113476], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {2: ['football', [0, 2, 1], ['football', 'football', 'cricket'], [6.665473288590343, 6.666211413750875, 6.741285672838174], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {3: ['rugby', [2, 1, 0], ['football', 'cricket', 'football'], [6.468995457982604, 6.616508102771298, 6.6743702763363535], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {4: ['tennis', [1, 2, 0], ['cricket', 'football', 'football'], [6.695635677350568, 6.89665714012756, 6.9943506601192285], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {5: ['athletics', [1, 2, 0], ['cricket', 'football', 'football'], [6.8620256743532435, 6.89642461792779, 6.996100808801902], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {6: ['football', [2, 0, 1], ['football', 'football', 'cricket'], [6.922668675327721, 7.197023953131772, 7.235113485654675], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {7: ['football', [2, 1, 0], ['football', 'cricket', 'football'], [6.081091904004365, 6.3127751996194, 6.463785248912359], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {8: ['football', [2, 0, 1], ['football', 'football', 'cricket'], [7.465358111502782, 7.4865332610350315, 7.5159326767903565], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {9: ['football', [0, 2, 1], ['football', 'football', 'cricket'], [6.151630398033891, 6.310046900931123, 6.945695481541881], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {10: ['football', [0, 2, 1], ['football', 'football', 'cricket'], [6.785139739392936, 7.041527938498889, 7.106721343304875], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {11: ['cricket', [1, 2, 0], ['cricket', 'football', 'football'], [6.34582882677216, 7.001385104602083, 7.400571323021152], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {12: ['tennis', [0, 1, 2], ['football', 'cricket', 'football'], [7.6006231527005195, 7.716782835397315, 7.780575745962196], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {13: ['football', [0, 2, 1], ['football', 'football', 'cricket'], [6.759662830495171, 6.88941926188718, 7.08364760769283], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {14: ['football', [0, 2, 1], ['football', 'football', 'cricket'], [5.878138614856298, 6.025701846865649, 6.4033391492042995], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {15: ['football', [0, 2, 1], ['football', 'football', 'cricket'], [6.5094109694183855, 6.594691405981681, 6.828124068793274], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {16: ['football', [2, 1, 0], ['football', 'cricket', 'football'], [6.087857428537418, 6.481919234914751, 6.77586394729441], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {17: ['athletics', [2, 1, 0], ['football', 'cricket', 'football'], [6.265083220937257, 6.726187432580267, 7.457681573573159], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {18: ['cricket', [1, 2, 0], ['cricket', 'football', 'football'], [6.490251720060819, 6.724568562996989, 7.22009671133413], [['football'], ['football'], ['football'], ['football'], ['football']]]}, {19: ['rugby', [2, 1, 0], ['football', 'cricket', 'football'], [6.776325596414108, 6.797738874945792, 6.986706323200539], [['football'], ['football'], ['football'], ['football'], ['football']]]}]\n"
     ]
    }
   ],
   "source": [
    "## To run as batch job\n",
    "\n",
    "\n",
    "#imports:\n",
    "\n",
    "# file imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "import os\n",
    "from scipy.optimize import linprog\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from gensim.models import KeyedVectors\n",
    "import sklearn\n",
    "import scipy\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "print(\"check 1: Imports done\\n\")\n",
    "\n",
    "def sentence_preprocess(embed_dict, sentence,lowercase = 1, strip_punctuation = 1,  remove_stopwords = 1,removedigit = 1):\n",
    "    ''' 1 : True, 0 : False : Lowercase, Strip puncutation, Remove Stopwords, removedigit'''\n",
    "\n",
    "    stop_words = list(stopwords.words('english'))\n",
    "\n",
    "    if lowercase == 1:\n",
    "        sentence = sentence.lower()\n",
    "\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "\n",
    "    if strip_punctuation == 1 and removedigit == 1:\n",
    "        sentence_words = [word for word in sentence_words if word.isalpha()] \n",
    "        \n",
    "\n",
    "\n",
    "    if remove_stopwords == 1:\n",
    "        sentence_words = [word for word in sentence_words if not word in stop_words]\n",
    "    \n",
    "    ## to remove those words which are not in the embeddings that we have.\n",
    "    \n",
    "    sentence_words = [word for word in sentence_words if word in embed_dict.keys()]\n",
    "\n",
    "\n",
    "\n",
    "    return sentence_words\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "embeddingtype = None\n",
    "embd_model = None\n",
    "\n",
    "\n",
    "\n",
    "## to load from embedding text files:\n",
    "## have used this to load glove vectors and not word2vec\n",
    "\n",
    "def load_glove(embeddingtype):\n",
    "    \n",
    "    if embeddingtype == 3:\n",
    "        i = 300\n",
    "    if embeddingtype == 4:\n",
    "        i = 200\n",
    "    if embeddingtype == 5:\n",
    "        i = 100\n",
    "    if embeddingtype == 6:\n",
    "        i = 50\n",
    "    \n",
    "    \n",
    "    embeddings_dict = defaultdict(lambda:np.zeros(i)) \n",
    "    # defaultdict to take care of OOV words.\n",
    "    \n",
    "    with open(f\"../../../Amit Pandey/wmd_lite/files/glove.6B.{i}d.txt\",'r') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            embeddings_dict[word] = vector\n",
    "        \n",
    "    return embeddings_dict\n",
    "\n",
    "\n",
    "def embeddings_setup(newembeddingtype):\n",
    "    \n",
    "    \n",
    "    global embeddingtype\n",
    "    global embd_model\n",
    "    \n",
    "    \n",
    "    '''to avoid loading all the embeddings in the memory.'''\n",
    "    \n",
    "    ''''## Note : we are finding the embd matrix two times, ie once for each sentence in\n",
    "        ## the pair of sentences.\n",
    "        ## so this happens that embedding type is changed when find_embmatrix is called\n",
    "        ## by the first sentence.\n",
    "        The above line doesnt matter now as we not calling find_embmatrix , instead we setting up.\n",
    "    '''\n",
    "        \n",
    "        \n",
    "        \n",
    "    if ( embeddingtype != newembeddingtype):\n",
    "        #print(\"embdtype  entered :\", embeddingtype != newembtype,\"\\n\")\n",
    "        #print(\"embd_model type changed to :\", type(embd_model),\"\\n\" )\n",
    "        \n",
    "        embeddingtype = newembeddingtype\n",
    "        \n",
    "        #embd_model = embeddings_setup(embeddingtype) #adictionary\n",
    "        \n",
    "        #print(\"embd_model type changed to :\", type(embd_model),\"\\n\" )\n",
    "        #to make sure that we don't download the embeddings again and again,\n",
    "        # we will check if the embedding type is same as the old one\n",
    "        # and update global embd_model, vrna next time vo use hi nhi ho payega.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if embeddingtype == 1:\n",
    "        embedding = KeyedVectors.load('google300w2v.kv', mmap='r')\n",
    "        ## This will be slower but will prevent kernel from crashing.\n",
    "        \n",
    "        ## comment the above line and uncomment this if you have sufficient RAM:\n",
    "        \n",
    "        #w2v_emb = gensim.downloader.load('word2vec-google-news-300')\n",
    "        \n",
    "    if embeddingtype == 2:\n",
    "        print('Normalised word2vec not loaded, will get it soon')\n",
    "        embedding = None\n",
    "    \n",
    "    if embeddingtype in (3,4,5,6):\n",
    "        embedding = load_glove(embeddingtype)\n",
    "        \n",
    "    \n",
    "    embd_model = embedding\n",
    "    \n",
    "    \n",
    "        \n",
    "def find_embdMatrix(sentence):\n",
    "    global embeddingtype\n",
    "    global embd_model\n",
    "    #print(\" global embedding type being passed is :\", embeddingtype,\"\\n\")\n",
    "    #print(\"embedding type received by the find emb matrix is :\", newembtype,\"\\n\")\n",
    "    #print(\"embd model type is :\", type(embd_model),\"\\n\")\n",
    "    \n",
    "    sent_mtx = []\n",
    "    \n",
    "    \n",
    "    ##commented lines moved to embedding setup.\n",
    "    \n",
    "#     ''''## Note : we are finding the embd matrix two times, ie once for each sentence in\n",
    "#     ## the pair of sentences.\n",
    "#     ## so this happens that embedding type is changed when find_embmatrix is called\n",
    "#     ## by the first sentence\n",
    "#     '''\n",
    "#     if ( embeddingtype != newembtype):\n",
    "#         print(\"if embdtype part entered :\", embeddingtype != newembtype,\"\\n\")\n",
    "        \n",
    "#         embeddingtype = newembtype\n",
    "#         embd_model = embeddings_setup(embeddingtype) #adictionary\n",
    "        \n",
    "#         print(\"embd_model type changed to :\", type(embd_model),\"\\n\" )\n",
    "#     #to make sure that we don't download the embeddings again and again,\n",
    "#     # we will check if the embedding type is same as the old one\n",
    "#     # and update global embd_model, vrna next time vo use hi nhi ho payega.\n",
    "    \n",
    "    #print(\"embd_model type changed to :\", type(embd_model),\"\\n\" )\n",
    "    for word in sentence:\n",
    "        word_emb = embd_model[word]\n",
    "        sent_mtx.append(word_emb)\n",
    "    \n",
    "    sent_mtx = np.array(sent_mtx).reshape(len(sentence),-1)\n",
    "\n",
    "    return sent_mtx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def wasserstein_distance(pi, qj, D, cost = 'min'):\n",
    "        \"\"\"Find Wasserstein distance through linear programming\n",
    "        p.shape=[m], q.shape=[n], D.shape=[m, n]\n",
    "    \n",
    "        suppose doc1 has m words and doc2 has n words, then an mxn array would be formed, \n",
    "        having distance of each word in doc1 to that of doc2.\n",
    "    \n",
    "    \n",
    "    \n",
    "        p.sum()=1, q.sum()=1, p[0,1], q[0,1]\n",
    "        \"\"\"\n",
    "        A_eq = [] # a list which will later be converted to array after appending.\n",
    "        for i in range(len(pi)): # len = number of words.\n",
    "            A = np.zeros_like(D) # a 2d array made with the shape of D.  \n",
    "            A[i, :] = 1 \n",
    "            #print(\"Dshape, len pi till here :\",D.shape,len(pi),\"\\n\")\n",
    "            \n",
    "            # to make summation over \"i\" of Tij = pi, ie total / sum of outflow\n",
    "            ## from one word is equal to its pi (normalized bag of word/ frequency/density)\n",
    "            ## ex : if 2x3 D:\n",
    "            ##T1,1 + T1,2 + T1,3 + 0 T2,1 + 0 T2,2 + 0 T2,3 = P1 and so on for every i,\n",
    "            ## ie for each word in the doc1\n",
    "            \n",
    "            \n",
    "            #print(\"A.shape\", A.shape,\"\\n\")\n",
    "            A_eq.append(A.reshape(-1)) ## reshape(-1) flatens and then appending in A_eq.\n",
    "            \n",
    "            #print(A_eq,\"Aeq\\n\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            ## A_eq will be (m+n)x(m.n)\n",
    "    \n",
    "        for i in range(len(qj)):\n",
    "            A = np.zeros_like(D)\n",
    "            A[:, i] = 1 ## summation over \"j\" this time, so this time for different rows, \n",
    "            ## over a column \"j\" which refers to doc2, ie total incoming flow = qj density\n",
    "            A_eq = list(A_eq)\n",
    "            A_eq.append(A.reshape(-1))\n",
    "            A_eq = np.array(A_eq)\n",
    "        \n",
    "        #print(A_eq.shape,A_eq)\n",
    "       \n",
    "        b_eq = np.concatenate([pi, qj])\n",
    "        D = D.reshape(-1)\n",
    "        #print(\"Dshape:\",D.shape)\n",
    "        if cost == 'max':\n",
    "            D = D*(-1)\n",
    "        \n",
    "        result = linprog(D, A_eq=A_eq[:-1], b_eq=b_eq[:-1]) ## removing redundant to make \n",
    "        ## solution more robust.\n",
    "        return np.absolute(result.fun), result.x , D.reshape((len(pi),len(qj)))  ## fun returns the final optimized value, x returns each value of xi,j that is the array\n",
    "\n",
    "    \n",
    "def relaxed_distance(pi,qj,D,cost='min'):\n",
    "    \n",
    "    # to find relaxed we just add the min/max cost directly using the least distance for pi to qj.\n",
    "    \n",
    "    # D is calculated from P to Q ie P in rows and Q in columns, To find Q to P we will transpose \n",
    "    if cost == 'min':\n",
    "        p_to_q = np.dot(D.min(axis=1),pi)\n",
    "        q_to_p = np.dot(D.T.min(axis=1),qj)\n",
    "        \n",
    "        return max(p_to_q,q_to_p)\n",
    "    \n",
    "    if cost == 'max':\n",
    "        \n",
    "        p_to_q = np.dot(D.max(axis=1),pi)\n",
    "        q_to_p = np.dot(D.T.max(axis=1),qj)\n",
    "        \n",
    "        return min(p_to_q,q_to_p), None, D\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "class WMD:\n",
    "    \n",
    "    ''' wmd type = normal/relaxed, costtype = min/max.\n",
    "    Enter Two sentence strings, cost = max if you want to try \n",
    "    max cost max flow version, embeddingtype = 1 for word2vec, 2 = normalized\n",
    "    word2vec, 3 = glove300d, 4 = glove200d, 5 = glove100d 6 = glove50d'''\n",
    "    \n",
    "    def __init__(self,embeddingtype, wmd_type = 'normal', costtype='min'):\n",
    "        \n",
    "        \n",
    "        self.cost = costtype\n",
    "        \n",
    "        self.embeddingtype = embeddingtype \n",
    "        self.wmd_type = wmd_type\n",
    "        \n",
    "        \n",
    "        ## setting up the embeddings\n",
    "        \n",
    "        embeddings_setup(self.embeddingtype)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #def word_count(self):\n",
    "#         self.sent1_dic = defaultdict(int)\n",
    "#         self.sent2_dic = defaultdict(int)\n",
    "        \n",
    "#         for word in sorted(sentence_preprocess(self.sent1)):\n",
    "#             self.sent1_dic[word] += 1\n",
    "            \n",
    "#         for word in sorted(sentence_preprocess(self.sent2)):\n",
    "#             self.sent2_dic[word] += 1\n",
    "        \n",
    "#         return dict(self.sent1_dic), dict(self.sent2_dic)\n",
    "\n",
    "\n",
    "\n",
    "#     def wasserstein_distance(self, pi, qj, D):\n",
    "#         \"\"\"Find Wasserstein distance through linear programming\n",
    "#         p.shape=[m], q.shape=[n], D.shape=[m, n]\n",
    "    \n",
    "#         suppose doc1 has m words and doc2 has n words, then an mxn array would be formed, \n",
    "#         having distance of each word in doc1 to that of doc2.\n",
    "    \n",
    "    \n",
    "    \n",
    "#         p.sum()=1, q.sum()=1, p[0,1], q[0,1]\n",
    "#         \"\"\"\n",
    "#         A_eq = [] # a list which will later be converted to array after appending.\n",
    "#         for i in range(len(pi)): # len = number of words.\n",
    "#             A = np.zeros_like(D) # a 2d array made with the shape of D.  \n",
    "#             A[i, :] = 1 \n",
    "#             # to make summation over \"i\" of Tij = pi, ie total / sum of outflow\n",
    "            ## from one word is equal to its pi (normalized bag of word/ frequency/density)\n",
    "            ## ex : if 2x3 D:\n",
    "            ##T1,1 + T1,2 + T1,3 + 0 T2,1 + 0 T2,2 + 0 T2,3 = P1 and so on for every i,\n",
    "            ## ie for each word in the doc1\n",
    "        \n",
    "#             A_eq.append(A.reshape(-1)) ## reshape(-1) flatens and then appending in A_eq.\n",
    "            ## A_eq will be (m+n)x(m.n)\n",
    "    \n",
    "#         for i in range(len(qj)):\n",
    "#             A = np.zeros_like(D)\n",
    "#             A[:, i] = 1 ## summation over \"j\" this time, so this time for different rows, \n",
    "#             ## over a column \"j\" which refers to doc2, ie total incoming flow = qj density\n",
    "#             A_eq.append(A.reshape(-1))\n",
    "#             A_eq = np.array(A_eq)\n",
    "        \n",
    "#         print(A_eq.shape,A_eq)\n",
    "       \n",
    "#         b_eq = np.concatenate([pi, qj])\n",
    "#         D = D.reshape(-1)\n",
    "#         if self.cost == 'max':\n",
    "#             D = D*(-1)\n",
    "        \n",
    "#         result = linprog(D, A_eq=A_eq[:-1], b_eq=b_eq[:-1]) ## removing redundant to make \n",
    "#         ## solution more robust.\n",
    "#         return result.fun, result.x  ## fun returns the final optimized value, x returns each value of xi,j that is the array\n",
    "\n",
    "    \n",
    "    def word_mover_distance(self,sentence1,sentence2):\n",
    "        \n",
    "        self.sent1 = sentence1\n",
    "        #print(self.sent1 ,\"\\n\")\n",
    "        self.sent2 = sentence2\n",
    "        #print(self.sent2 ,\"\\n\")\n",
    "        \n",
    "        \n",
    "        self.sent1_dic = defaultdict(int)\n",
    "        self.sent2_dic = defaultdict(int)\n",
    "        \n",
    "        for word in sorted(sentence_preprocess(embd_model,self.sent1)): # sorted to have better\n",
    "            self.sent1_dic[word] += 1 # idea of the sequence of the words. Creating BOW here\n",
    "            \n",
    "        for word in sorted(sentence_preprocess(embd_model,self.sent2)): #creating BOW from sorted sequence\n",
    "            self.sent2_dic[word] += 1\n",
    "        \n",
    "        \n",
    "        self.sent1_dic = dict(self.sent1_dic) # converted from default dict to dict.\n",
    "        self.sent2_dic = dict(self.sent2_dic) # because following operations work on dict\n",
    "        \n",
    "        \n",
    "        #print(self.sent1_dic ,\"\\n\")\n",
    "        #print(self.sent2_dic ,\"\\n\")\n",
    "        \n",
    "        \n",
    "        ## Now we will store a list/array of all the words in each sentence (in alphabetically sorted order)\n",
    "        ## we will store corresponding count, and then corresponding Normalised count.\n",
    "        self.sent1_words = np.array(list(self.sent1_dic.keys())) #dictionary keys converted to list than array\n",
    "        self.sent1_counts = np.array(list(self.sent1_dic.values()))\n",
    "        \n",
    "        self.sent2_words = np.array(list(self.sent2_dic.keys()))\n",
    "        self.sent2_counts = np.array(list(self.sent2_dic.values()))\n",
    "        \n",
    "        \n",
    "        #print(self.sent1_words ,\"\\n\")\n",
    "        #print(self.sent1_counts ,\"\\n\")\n",
    "        \n",
    "        #print(self.sent2_words ,\"\\n\")\n",
    "        #print(self.sent2_counts ,\"\\n\")\n",
    "        \n",
    "        #dictionary values cant be converted into an array directly, hence the\n",
    "        #list step.\n",
    "        \n",
    "        #print(\"embedding type being passed is :\", self.embeddingtype,\"\\n\")\n",
    "        self.sent1_embmtx = find_embdMatrix(self.sent1_words)\n",
    "        #print(self.sent1_embmtx.shape,\"sent1emb\\n\")\n",
    "        self.sent2_embmtx = find_embdMatrix(self.sent2_words)\n",
    "        #print(self.sent2_embmtx.shape,\"sent2emb\\n\")\n",
    "        \n",
    "        self.pi = self.sent1_counts/np.sum(self.sent1_counts) #NBOW step from BOW\n",
    "        #print(self.pi,\"self.pi\\n\")\n",
    "        self.qj = self.sent2_counts/np.sum(self.sent2_counts)\n",
    "        #print(self.qj,\"self.qj\\n\")\n",
    "        \n",
    "        self.D = np.sqrt(np.square(self.sent1_embmtx[:, None] - self.sent2_embmtx[None, :]).sum(axis=2)) \n",
    "        #print(self.D.shape,\"Dshape \\n\")\n",
    "        ## programmers sought used mean instead of sum.\n",
    "        ## scipy cdist can be used as well.\n",
    "        \n",
    "        if self.wmd_type == 'normal':\n",
    "            return wasserstein_distance(self.pi, self.qj, self.D, self.cost)\n",
    "        \n",
    "        \n",
    "        if self.wmd_type == 'relaxed':\n",
    "            return relaxed_distance(self.pi,self.qj,self.D,self.cost)\n",
    "\n",
    "        \n",
    "\n",
    "print(\"check 2 : function definitions \\n\")\n",
    "\n",
    "## KNN\n",
    "\n",
    "print(\" loading train and test dataset\\n\")\n",
    "\n",
    "Train_BBCsport_sent = np.load(\"../../../Amit Pandey/wmd_lite/files/Train_BBCsport_sent.npy\")\n",
    "Train_BBCsport_label = np.load(\"../../../Amit Pandey/wmd_lite/files/Train_BBCsport_label.npy\")\n",
    "Test_BBCsport_sent = np.load(\"../../../Amit Pandey/wmd_lite/files/Test_BBCsport_sent.npy\")\n",
    "Test_BBCsport_label = np.load(\"../../../Amit Pandey/wmd_lite/files/Test_BBCsport_label.npy\")\n",
    "\n",
    "\n",
    "# for i in range(10):\n",
    "#     print(Test_BBCsport_label[i],\"\\n\",Test_BBCsport_sent[i])\n",
    "    \n",
    "\n",
    "# print(\"##################Train details:\\n\")\n",
    "\n",
    "# for i in range(30):\n",
    "#     print(Train_BBCsport_label[i],\"\\n\",Train_BBCsport_sent[i])\n",
    "\n",
    "\n",
    "# embeddingtype = 3\n",
    "# model = WMD(embeddingtype,wmd_type = 'relaxed', costtype='max')\n",
    "\n",
    "            \n",
    "    \n",
    "no_testdocs = len(Test_BBCsport_sent)\n",
    "no_testlabels = len(Test_BBCsport_label)\n",
    "#no_testdocs,no_testlabels\n",
    "\n",
    "print(\"check 3 : dataset loaded \\n\")\n",
    "\n",
    "print(\" No of test docs and labels loaded:\",no_testdocs,\" \",no_testlabels,\"\\n\")\n",
    "\n",
    "print(\" No of train docs and labels loaded:\",len(Train_BBCsport_sent),\" \",len(Train_BBCsport_label),\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "actual_category = []\n",
    "predicted_category = []\n",
    "prediction_dictionary = {}\n",
    "\n",
    "## prediction_dictionary contains test sentence as key, and [['original lable'],[predicted labels for diff k],\n",
    "## , [index of top labels of train set],['distance of top 30 elements']]\n",
    "\n",
    "    \n",
    "\n",
    "print(\" Model initialization started wtih NORMAL WMD with MIN cost and glove vectors  \\n\")\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "embeddingtype = 3\n",
    "model = WMD(embeddingtype,wmd_type = 'normal', costtype='min')\n",
    "\n",
    "print(\" check 4: model initialization successful \\n\")\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "def predict_Category(i):\n",
    "    sentence = Test_BBCsport_sent[i]\n",
    "    print(f\"running test{i} \\n\")\n",
    "    #print(\"actual category :\", Test_BBCsport_label[i])\n",
    "    #actual_category.append(Test_BBCsport_label[i])\n",
    "    \n",
    "    distance_fromTrainset = []\n",
    "    \n",
    "    #for j in range (len(Train_BBCsport_sent)):\n",
    "        \n",
    "       \n",
    "    for j in range (3):\n",
    "        #print(f\"Train sent{i} \\n\")\n",
    "        ## Find totalcost ie distance between sentence passed from test set to each sentence \n",
    "        ## in training set. and then append in the list.\n",
    "        \n",
    "        #print(sentence)\n",
    "        #print(Train_BBCsport_sent[i])\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        Totalcost, Tcoeff, Distancematx = model.word_mover_distance(sentence,Train_BBCsport_sent[j])\n",
    "        #print(Totalcost)\n",
    "        distance_fromTrainset.append(Totalcost)\n",
    "        \n",
    "    distance_fromTrainset = np.array(distance_fromTrainset)\n",
    "    #print('distance from train set array:',distance_fromTrainset)\n",
    "    \n",
    "    arr1indx = distance_fromTrainset.argsort()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(\"Original Sentence : \\n\",sentence, \"\\n\",\"Distance and label sorted from test set\\n\",distance_fromTrainset[arr1indx[::1]], \"\\n\",Train_BBCsport_label[arr1indx[::1]],\"\\n\",\" Train Sentences: \\n\",Train_BBCsport_sent[arr1indx[::1]]) \n",
    "    \n",
    "    print(\"Starting distance calculation############################### \\n\")\n",
    "    \n",
    "    ## Taking for different values of K\n",
    "    \n",
    "    #k = 5\n",
    "    sorted_distance_fromTrainset_k5 = distance_fromTrainset[arr1indx[::1]][:5]\n",
    "    sorted_labels_k5 = Train_BBCsport_label[arr1indx[::1]][:5]\n",
    "    \n",
    "    predicted_cat_k5 = scipy.stats.mode(sorted_labels_k5)[0]\n",
    "    print(f\"pred 5 for test {i} \",predicted_cat_k5)\n",
    "   \n",
    "\n",
    "    #k = 7\n",
    "    sorted_distance_fromTrainset_k7 = distance_fromTrainset[arr1indx[::1]][:7]\n",
    "    sorted_labels_k7 = Train_BBCsport_label[arr1indx[::1]][:7]\n",
    "    \n",
    "    predicted_cat_k7 = scipy.stats.mode(sorted_labels_k7)[0]\n",
    "    print(f\"pred 7 for test {i} \",predicted_cat_k7)\n",
    "\n",
    "    #k = 11\n",
    "    sorted_distance_fromTrainset_k11 = distance_fromTrainset[arr1indx[::1]][:11]\n",
    "    sorted_labels_k11 = Train_BBCsport_label[arr1indx[::1]][:11]\n",
    "    \n",
    "    predicted_cat_k11 = scipy.stats.mode(sorted_labels_k11)[0]\n",
    "    print(f\"pred 11 for test {i} \",predicted_cat_k11)\n",
    "\n",
    "    #k = 15\n",
    "    sorted_distance_fromTrainset_k15 = distance_fromTrainset[arr1indx[::1]][:15]\n",
    "    sorted_labels_k15 = Train_BBCsport_label[arr1indx[::1]][:15]\n",
    "    \n",
    "    predicted_cat_k15 = scipy.stats.mode(sorted_labels_k15)[0]\n",
    "    print(f\"pred 15 for test {i} \",predicted_cat_k15)\n",
    "\n",
    "    #k = 21\n",
    "    sorted_distance_fromTrainset_k21 = distance_fromTrainset[arr1indx[::1]][:21]\n",
    "    sorted_labels_k21 = Train_BBCsport_label[arr1indx[::1]][:21]\n",
    "    \n",
    "    predicted_cat_k21 = scipy.stats.mode(sorted_labels_k21)[0]\n",
    "    print(f\"pred 21 for test {i} \",predicted_cat_k21)\n",
    "\n",
    "\n",
    "    #print(sorted_distance_fromTrainset,sorted_labels)\n",
    "\n",
    "    prediction_dictionary[i] = [Test_BBCsport_label[i],\n",
    "                                arr1indx[:30].tolist(),\n",
    "                                Train_BBCsport_label[arr1indx[::1]][:30].tolist(),\n",
    "                                distance_fromTrainset[arr1indx[::1]][:30].tolist(),\n",
    "                                [predicted_cat_k5.tolist(),predicted_cat_k7.tolist(), predicted_cat_k11.tolist(),predicted_cat_k15.tolist(),\n",
    "                                 predicted_cat_k21.tolist()]]\n",
    "    \n",
    "    return prediction_dictionary\n",
    "    #return np.array([predicted_cat_k5,predicted_cat_k7, predicted_cat_k11,predicted_cat_k15,predicted_cat_k21])#, distance_fromTrainset[arr1indx[::1]],Train_BBCsport_label[arr1indx[::1]]\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "# no_testdocs = len(Test_BBCsport_sent)\n",
    "# no_testlabels = len(Test_BBCsport_label)\n",
    "#no_testdocs,no_testlabels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#predicted_categories_list = []\n",
    "# for i in range (1,2):\n",
    "#     print(Test_BBCsport_label[i])\n",
    "#     actual_categories.append(Test_BBCsport_label[i]) \n",
    "#     pred_category = predict_Category(Test_BBCsport_sent[i])\n",
    "#     print(pred_category)\n",
    "#     predicted_categories_list.append(pred_category)\n",
    "\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "with Pool(20) as p :\n",
    "        predicted_Categorieslist = p.map(predict_Category,range(20))\n",
    "        \n",
    "#print(predicted_Categorieslist)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "et = time.time()\n",
    "\n",
    "print(\"\\n time taken: \",et-st)\n",
    "print(\"..................\\n\\n\\n\")\n",
    "print(predicted_Categorieslist)\n",
    "\n",
    "\n",
    "\n",
    "# a_file = open(\"wmdresult.json\", \"w\")\n",
    "# json.dump(predicted_Categorieslist, a_file)\n",
    "# a_file.close()\n",
    "\n",
    "# # a_file = open(\"wmdresult.json\", \"r\")\n",
    "# # output = a_file.read()\n",
    "# # print(output)\n",
    "\n",
    "# # a_file.close()\n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    " \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8a5f0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home2/dhawals1939/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home2/dhawals1939/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6132f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['files', '.ipynb_checkpoints', 'src', 'Files_Detail.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../../../Amit Pandey/wmd_lite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a99ef25e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../scratch/Dhawalop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6732/704974263.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../../scratch/Dhawalop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../scratch/Dhawalop'"
     ]
    }
   ],
   "source": [
    "os.listdir(\"../../../scratch/Dhawalop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d2c2e0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../../../scratch/Dhawalop/wmdop/filename.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6732/1685627973.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# a = {'hello': 'world'}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../../../scratch/Dhawalop/wmdop/filename.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_dictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../../../scratch/Dhawalop/wmdop/filename.pickle'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# a = {'hello': 'world'}\n",
    "\n",
    "with open('../../../../../scratch/Dhawalop/wmdop/filename.pickle', 'wb') as handle:\n",
    "    pickle.dump(prediction_dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('../../../../../scratch/Dhawalop/wmdop/filename.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "\n",
    "print (a == b)\n",
    "print(prediction_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2bb636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
