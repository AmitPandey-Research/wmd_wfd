{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b6284a9",
   "metadata": {},
   "source": [
    "## This notebook consists of :\n",
    "\n",
    "1) wmd implementation as direct transportation problem.(along with functions for datapreprocessing)<br>\n",
    "2) our experiment of using max cost<br>\n",
    "3) file loaders to load dataset/embedding of glove.<br>\n",
    "\n",
    "We may use keyedvectors word2vec as otherwise the gensim loader is crashing the jupyter kernel on ada. \n",
    "\n",
    "### Following experimentations :\n",
    "1) direct wmd for the three original paper sentences.<br>\n",
    "2) our max cost experimentation.<br>\n",
    "Repeated with glove vector of 200d and 50d."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96995e6b",
   "metadata": {},
   "source": [
    "Steps :\n",
    "1) Enter two sentences <br>\n",
    "2) Preprocess : tokenize and lemmatize to get a list of words. <br>\n",
    "3) Create a dictionary for count of every word in each sentence.<br>\n",
    "4) Sort alphabetically<br>\n",
    "5) Pick one dictionary at a time, create embedding matrix for each sentence by picking one word from the sentence, find its embedding and append in the list. At the same time append its count in the p/q matrix ie nbow.<br>\n",
    "6) Proceed to find min/max cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed6c316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports:\n",
    "\n",
    "# file imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "import os\n",
    "from scipy.optimize import linprog\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from gensim.models import KeyedVectors\n",
    "import sklearn\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee50c6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['files', '.ipynb_checkpoints', 'src', 'Miniconda3-latest-Linux-x86_64.sh']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6223a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_preprocess(sentence,lowercase = 1, strip_punctuation = 1, remove_stopwords = 1, embed_dict, removedigit = 1):\n",
    "    ''' 1 : True, 0 : False : Lowercase, Strip puncutation, Remove Stopwords, removedigit'''\n",
    "\n",
    "    stop_words = list(stopwords.words('english'))\n",
    "\n",
    "    if lowercase == 1:\n",
    "        sentence = sentence.lower()\n",
    "\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "\n",
    "    if strip_punctuation == 1 and removedigit == 1:\n",
    "        sentence_words = [word for word in sentence_words if word.isalpha()] \n",
    "        \n",
    "\n",
    "\n",
    "    if remove_stopwords == 1:\n",
    "        sentence_words = [word for word in sentence_words if not word in stop_words]\n",
    "    \n",
    "    \n",
    "    sentence_words = [word for word in sentence_words if word in embed_dict.keys()]\n",
    "\n",
    "\n",
    "\n",
    "    return sentence_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "efcf2c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingtype = None\n",
    "embd_model = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ea84d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to load from embedding text files:\n",
    "## have used this to load glove vectors and not word2vec\n",
    "\n",
    "def load_glove(embeddingtype):\n",
    "    \n",
    "    if embeddingtype == 3:\n",
    "        i = 300\n",
    "    if embeddingtype == 4:\n",
    "        i = 200\n",
    "    if embeddingtype == 5:\n",
    "        i = 100\n",
    "    if embeddingtype == 6:\n",
    "        i = 50\n",
    "    \n",
    "    \n",
    "    embeddings_dict = defaultdict(lambda:np.zeros(i)) \n",
    "    # defaultdict to take care of OOV words.\n",
    "    \n",
    "    with open(f\"../test/glove.6B.{i}d.txt\",'r') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            embeddings_dict[word] = vector\n",
    "        \n",
    "    return embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6feebf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_setup(embeddingtype):\n",
    "    '''to avoid loading all the embeddings in the memory.'''\n",
    "    \n",
    "    if embeddingtype == 1:\n",
    "        embedding = KeyedVectors.load('google300w2v.kv', mmap='r')\n",
    "        ## This will be slower but will prevent kernel from crashing.\n",
    "        \n",
    "        ## comment the above line and uncomment this if you have sufficient RAM:\n",
    "        \n",
    "        #w2v_emb = gensim.downloader.load('word2vec-google-news-300')\n",
    "        \n",
    "    if embeddingtype == 2:\n",
    "        print('Normalised word2vec not loaded, will get it soon')\n",
    "        embedding = None\n",
    "    \n",
    "    if embeddingtype in (3,4,5,6):\n",
    "        embedding = load_glove(embeddingtype)\n",
    "        \n",
    "    \n",
    "    return embedding\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "596481e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_embdMatrix(sentence, newembtype):\n",
    "    global embeddingtype\n",
    "    global embd_model\n",
    "    print(\" global embedding type being passed is :\", embeddingtype,\"\\n\")\n",
    "    print(\"embedding type received by the find emb matrix is :\", newembtype,\"\\n\")\n",
    "    print(\"embd model type is :\", type(embd_model),\"\\n\")\n",
    "    \n",
    "    sent_mtx = []\n",
    "    ## Note : we are finding the embd matrix two times, ie once for each sentence in\n",
    "    ## the pair of sentences.\n",
    "    ## so this happens that embedding type is changed when find_embmatrix is called\n",
    "    ## by the first sentence \n",
    "    if ( embeddingtype != newembtype):\n",
    "        print(\"if embdtype part entered :\", embeddingtype != newembtype,\"\\n\")\n",
    "        \n",
    "        embeddingtype = newembtype\n",
    "        embd_model = embeddings_setup(embeddingtype)\n",
    "        \n",
    "        print(\"embd_model type changed to :\", type(embd_model),\"\\n\" )\n",
    "    #to make sure that we don't download the embeddings again and again,\n",
    "    # we will check if the embedding type is same as the old one\n",
    "    # and update global embd_model, vrna next time vo use hi nhi ho payega.\n",
    "    \n",
    "    print(\"embd_model type changed to :\", type(embd_model),\"\\n\" )\n",
    "    for word in sentence:\n",
    "        word_emb = embd_model[word]\n",
    "        sent_mtx.append(word_emb)\n",
    "    \n",
    "    sent_mtx = np.array(sent_mtx).reshape(len(sentence),-1)\n",
    "\n",
    "    return sent_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac3b03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    " def wasserstein_distance(pi, qj, D, cost = 'min'):\n",
    "        \"\"\"Find Wasserstein distance through linear programming\n",
    "        p.shape=[m], q.shape=[n], D.shape=[m, n]\n",
    "    \n",
    "        suppose doc1 has m words and doc2 has n words, then an mxn array would be formed, \n",
    "        having distance of each word in doc1 to that of doc2.\n",
    "    \n",
    "    \n",
    "    \n",
    "        p.sum()=1, q.sum()=1, p∈[0,1], q∈[0,1]\n",
    "        \"\"\"\n",
    "        A_eq = [] # a list which will later be converted to array after appending.\n",
    "        for i in range(len(pi)): # len = number of words.\n",
    "            A = np.zeros_like(D) # a 2d array made with the shape of D.  \n",
    "            A[i, :] = 1 \n",
    "            print(\"Dshape, len pi till here :\",D.shape,len(pi),\"\\n\")\n",
    "            \n",
    "            # to make summation over \"i\" of Tij = pi, ie total / sum of outflow\n",
    "            ## from one word is equal to its pi (normalized bag of word/ frequency/density)\n",
    "            ## ex : if 2x3 D:\n",
    "            ##T1,1 + T1,2 + T1,3 + 0 T2,1 + 0 T2,2 + 0 T2,3 = P1 and so on for every i,\n",
    "            ## ie for each word in the doc1\n",
    "            print(\"A.shape\", A.shape,\"\\n\")\n",
    "            A_eq.append(A.reshape(-1)) ## reshape(-1) flatens and then appending in A_eq.\n",
    "            print(A_eq,\"Aeq\\n\")\n",
    "            ## A_eq will be (m+n)x(m.n)\n",
    "    \n",
    "        for i in range(len(qj)):\n",
    "            A = np.zeros_like(D)\n",
    "            A[:, i] = 1 ## summation over \"j\" this time, so this time for different rows, \n",
    "            ## over a column \"j\" which refers to doc2, ie total incoming flow = qj density\n",
    "            A_eq = list(A_eq)\n",
    "            A_eq.append(A.reshape(-1))\n",
    "            A_eq = np.array(A_eq)\n",
    "        \n",
    "        print(A_eq.shape,A_eq)\n",
    "       \n",
    "        b_eq = np.concatenate([pi, qj])\n",
    "        D = D.reshape(-1)\n",
    "        #print(\"Dshape:\",D.shape)\n",
    "        if cost == 'max':\n",
    "            D = D*(-1)\n",
    "        \n",
    "        result = linprog(D, A_eq=A_eq[:-1], b_eq=b_eq[:-1]) ## removing redundant to make \n",
    "        ## solution more robust.\n",
    "        return np.absolute(result.fun), result.x , D.reshape((len(pi),len(qj)))  ## fun returns the final optimized value, x returns each value of xi,j that is the array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b0c04610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relaxed_distance(pi,qj,D,cost='min'):\n",
    "    \n",
    "    # to find relaxed we just add the min/max cost directly using the least distance for pi to qj.\n",
    "    \n",
    "    # D is calculated from P to Q ie P in rows and Q in columns, To find Q to P we will transpose \n",
    "    if cost == 'min':\n",
    "        p_to_q = np.dot(D.min(axis=1),pi)\n",
    "        q_to_p = np.dot(D.T.min(axis=1),qj)\n",
    "        \n",
    "        return max(p_to_q,q_to_p)\n",
    "    \n",
    "    if cost == 'max':\n",
    "        \n",
    "        p_to_q = np.dot(D.max(axis=1),pi)\n",
    "        q_to_p = np.dot(D.T.max(axis=1),qj)\n",
    "        \n",
    "        return min(p_to_q,q_to_p)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ee465a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WMD:\n",
    "    \n",
    "    ''' Enter Two sentence strings, cost = max if you want to try \n",
    "    max cost max flow version, embeddingtype = 1 for word2vec, 2 = normalized\n",
    "    word2vec, 3 = glove300d, 4 = glove200d, 5 = glove100d 6 = glove50d'''\n",
    "    \n",
    "    def __init__(self,embeddingtype, wmd_type = 'normal', costtype='min'):\n",
    "        \n",
    "        \n",
    "        self.cost = costtype\n",
    "        \n",
    "        self.embeddingtype = embeddingtype \n",
    "        self.wmd_type = wmd_type\n",
    "        \n",
    "    #def word_count(self):\n",
    "#         self.sent1_dic = defaultdict(int)\n",
    "#         self.sent2_dic = defaultdict(int)\n",
    "        \n",
    "#         for word in sorted(sentence_preprocess(self.sent1)):\n",
    "#             self.sent1_dic[word] += 1\n",
    "            \n",
    "#         for word in sorted(sentence_preprocess(self.sent2)):\n",
    "#             self.sent2_dic[word] += 1\n",
    "        \n",
    "#         return dict(self.sent1_dic), dict(self.sent2_dic)\n",
    "\n",
    "\n",
    "\n",
    "#     def wasserstein_distance(self, pi, qj, D):\n",
    "#         \"\"\"Find Wasserstein distance through linear programming\n",
    "#         p.shape=[m], q.shape=[n], D.shape=[m, n]\n",
    "    \n",
    "#         suppose doc1 has m words and doc2 has n words, then an mxn array would be formed, \n",
    "#         having distance of each word in doc1 to that of doc2.\n",
    "    \n",
    "    \n",
    "    \n",
    "#         p.sum()=1, q.sum()=1, p∈[0,1], q∈[0,1]\n",
    "#         \"\"\"\n",
    "#         A_eq = [] # a list which will later be converted to array after appending.\n",
    "#         for i in range(len(pi)): # len = number of words.\n",
    "#             A = np.zeros_like(D) # a 2d array made with the shape of D.  \n",
    "#             A[i, :] = 1 \n",
    "#             # to make summation over \"i\" of Tij = pi, ie total / sum of outflow\n",
    "            ## from one word is equal to its pi (normalized bag of word/ frequency/density)\n",
    "            ## ex : if 2x3 D:\n",
    "            ##T1,1 + T1,2 + T1,3 + 0 T2,1 + 0 T2,2 + 0 T2,3 = P1 and so on for every i,\n",
    "            ## ie for each word in the doc1\n",
    "        \n",
    "#             A_eq.append(A.reshape(-1)) ## reshape(-1) flatens and then appending in A_eq.\n",
    "            ## A_eq will be (m+n)x(m.n)\n",
    "    \n",
    "#         for i in range(len(qj)):\n",
    "#             A = np.zeros_like(D)\n",
    "#             A[:, i] = 1 ## summation over \"j\" this time, so this time for different rows, \n",
    "#             ## over a column \"j\" which refers to doc2, ie total incoming flow = qj density\n",
    "#             A_eq.append(A.reshape(-1))\n",
    "#             A_eq = np.array(A_eq)\n",
    "        \n",
    "#         print(A_eq.shape,A_eq)\n",
    "       \n",
    "#         b_eq = np.concatenate([pi, qj])\n",
    "#         D = D.reshape(-1)\n",
    "#         if self.cost == 'max':\n",
    "#             D = D*(-1)\n",
    "        \n",
    "#         result = linprog(D, A_eq=A_eq[:-1], b_eq=b_eq[:-1]) ## removing redundant to make \n",
    "#         ## solution more robust.\n",
    "#         return result.fun, result.x  ## fun returns the final optimized value, x returns each value of xi,j that is the array\n",
    "\n",
    "    \n",
    "    def word_mover_distance(self,sentence1,sentence2, ):\n",
    "        \n",
    "        self.sent1 = sentence1\n",
    "        print(self.sent1 ,\"\\n\")\n",
    "        self.sent2 = sentence2\n",
    "        print(self.sent2 ,\"\\n\")\n",
    "        \n",
    "        \n",
    "        self.sent1_dic = defaultdict(int)\n",
    "        self.sent2_dic = defaultdict(int)\n",
    "        \n",
    "        for word in sorted(sentence_preprocess(self.sent1)): # sorted to have better\n",
    "            self.sent1_dic[word] += 1 # idea of the sequence of the words.\n",
    "            \n",
    "        for word in sorted(sentence_preprocess(self.sent2)):\n",
    "            self.sent2_dic[word] += 1\n",
    "        \n",
    "        \n",
    "        self.sent1_dic = dict(self.sent1_dic) # converted from default dict to dict.\n",
    "        self.sent2_dic = dict(self.sent2_dic) # because following operations work on dict\n",
    "        \n",
    "        \n",
    "        print(self.sent1_dic ,\"\\n\")\n",
    "        print(self.sent2_dic ,\"\\n\")\n",
    "        \n",
    "        self.sent1_words = np.array(list(self.sent1_dic.keys()))\n",
    "        self.sent1_counts = np.array(list(self.sent1_dic.values()))\n",
    "        \n",
    "        self.sent2_words = np.array(list(self.sent2_dic.keys()))\n",
    "        self.sent2_counts = np.array(list(self.sent2_dic.values()))\n",
    "        \n",
    "        \n",
    "        print(self.sent1_words ,\"\\n\")\n",
    "        print(self.sent1_counts ,\"\\n\")\n",
    "        \n",
    "        print(self.sent2_words ,\"\\n\")\n",
    "        print(self.sent2_counts ,\"\\n\")\n",
    "        \n",
    "        #dictionary values cant be converted into an array directly, hence the\n",
    "        #list step.\n",
    "        \n",
    "        print(\"embedding type being passed is :\", self.embeddingtype,\"\\n\")\n",
    "        self.sent1_embmtx = find_embdMatrix(self.sent1_words, self.embeddingtype)\n",
    "        print(self.sent1_embmtx.shape,\"sent1emb\\n\")\n",
    "        self.sent2_embmtx = find_embdMatrix(self.sent2_words, self.embeddingtype)\n",
    "        print(self.sent2_embmtx.shape,\"sent2emb\\n\")\n",
    "        \n",
    "        self.pi = self.sent1_counts/np.sum(self.sent1_counts)\n",
    "        print(self.pi,\"self.pi\\n\")\n",
    "        self.qj = self.sent2_counts/np.sum(self.sent2_counts)\n",
    "        print(self.qj,\"self.pi\\n\")\n",
    "        \n",
    "        self.D = np.sqrt(np.square(self.sent1_embmtx[:, None] - self.sent2_embmtx[None, :]).sum(axis=2)) \n",
    "        print(self.D.shape,\"Dshape \\n\")\n",
    "        ## programmers sought used mean instead of sum.\n",
    "        ## scipy cdist can be used as well.\n",
    "        \n",
    "        if self.wmd_type == 'normal':\n",
    "            return wasserstein_distance(self.pi, self.qj, self.D, self.cost)\n",
    "        \n",
    "        \n",
    "        if self.wmd_type == 'relaxed':\n",
    "            return relaxed_distance(self.pi,self.qj,self.D,self.cost)\n",
    " \n",
    "             \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    " \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "075e167c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0])] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1])] Aeq\n",
      "\n",
      "(8, 16) [[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1]\n",
      " [1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1]]\n",
      "Dshape: (16,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.500000000120658,\n",
       " array([1.25000000e-01, 1.25000000e-01, 8.10264749e-12, 8.10301845e-12,\n",
       "        1.25000000e-01, 1.25000000e-01, 8.10264749e-12, 8.10301845e-12,\n",
       "        8.10233249e-12, 8.10233249e-12, 2.50000000e-01, 1.19639048e-11,\n",
       "        8.10196153e-12, 8.10196153e-12, 1.19633571e-11, 2.50000000e-01]),\n",
       " array([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 0, 1],\n",
       "        [1, 1, 1, 0]]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = [0.25,0.25,0.25,0.25]\n",
    "qi = [0.25,0.25,0.25,0.25]\n",
    "d = np.array([[1,1,1,1],[1,1,1,1],[1,1,0,1],[1,1,1,0]]).reshape((4,4))\n",
    "a,b,c = wasserstein_distance(pi,qi,d)\n",
    "a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c66d2c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"Obama speaks to the media in Illinois.\"\n",
    "sent2 = \"The President greets the press in Chicago.\"\n",
    "sent3 = \"The band gave a concert in Japan.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb9a13ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama speaks to the media in Illinois. \n",
      "\n",
      "The President greets the press in Chicago. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = WMD(sent1,sent2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb9e7585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'illinois': 1, 'media': 1, 'obama': 1, 'speaks': 1} \n",
      "\n",
      "{'chicago': 1, 'greets': 1, 'president': 1, 'press': 1} \n",
      "\n",
      "['illinois' 'media' 'obama' 'speaks'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "['chicago' 'greets' 'president' 'press'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "embedding type being passed is : 1 \n",
      "\n",
      " global embedding type being passed is : 1 \n",
      "\n",
      "embedding type received by the find emb matrix is : 1 \n",
      "\n",
      "embd model type is : <class 'gensim.models.keyedvectors.KeyedVectors'> \n",
      "\n",
      "embd_model type changed to : <class 'gensim.models.keyedvectors.KeyedVectors'> \n",
      "\n",
      "(4, 300) sent1emb\n",
      "\n",
      " global embedding type being passed is : 1 \n",
      "\n",
      "embedding type received by the find emb matrix is : 1 \n",
      "\n",
      "embd model type is : <class 'gensim.models.keyedvectors.KeyedVectors'> \n",
      "\n",
      "embd_model type changed to : <class 'gensim.models.keyedvectors.KeyedVectors'> \n",
      "\n",
      "(4, 300) sent2emb\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "(4, 4) Dshape \n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "(8, 16) [[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]]\n",
      "Dshape: (16,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.3741232173489615,\n",
       " array([2.50000000e-01, 3.18531834e-11, 2.14184326e-11, 2.52857048e-11,\n",
       "        4.70801233e-12, 1.81424091e-11, 5.88324554e-11, 2.50000000e-01,\n",
       "        6.85027770e-11, 3.21133789e-11, 2.50000000e-01, 2.74871660e-11,\n",
       "        5.34556353e-12, 2.50000000e-01, 4.78527543e-11, 2.89110126e-11]),\n",
       " array([[3.169699 , 4.937704 , 4.357834 , 4.119726 ],\n",
       "        [4.4567947, 4.215941 , 3.366701 , 2.1343176],\n",
       "        [4.0367475, 5.5453153, 4.782619 , 4.6934934],\n",
       "        [4.7602735, 3.4098573, 3.7898932, 3.376263 ]], dtype=float32))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diss, T,mtx = model.word_mover_distance()\n",
    "diss,T,mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "08c932af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The band gave a concert in Japan. \n",
      "\n",
      "The President greets the press in Chicago. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = WMD(sent3,sent2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b05c3a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'band': 1, 'concert': 1, 'gave': 1, 'japan': 1} \n",
      "\n",
      "{'chicago': 1, 'greets': 1, 'president': 1, 'press': 1} \n",
      "\n",
      "['band' 'concert' 'gave' 'japan'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "['chicago' 'greets' 'president' 'press'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "(4, 300) sent1emb\n",
      "\n",
      "(4, 300) sent2emb\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "(4, 4) Dshape \n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "(8, 16) [[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]]\n",
      "Dshape: (16,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.883809542596161,\n",
       " array([3.48501400e-10, 1.65290340e-09, 2.49999999e-01, 8.68767734e-10,\n",
       "        3.28668785e-10, 3.40554971e-09, 8.32333805e-11, 2.49999998e-01,\n",
       "        3.36383594e-10, 2.49999997e-01, 2.45479080e-09, 2.60203117e-09,\n",
       "        2.50000001e-01, 3.34751925e-10, 3.32148598e-10, 3.46652947e-10]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NOTE : IMPORTANT\n",
    "\n",
    "## Do not rerun this as the code has been modified,\n",
    "## now the code returns three values. here we just using two values\n",
    "\n",
    "diss2,t2 = model2.word_mover_distance()\n",
    "diss2,t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d501a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## These values we got with modified code and they are same as the \n",
    "## previous one, so the code is working smoothly.\n",
    "\n",
    "\n",
    "# (3.883809542596161,\n",
    "#  array([3.48501400e-10, 1.65290340e-09, 2.49999999e-01, 8.68767734e-10,\n",
    "#         3.28668785e-10, 3.40554971e-09, 8.32333805e-11, 2.49999998e-01,\n",
    "#         3.36383594e-10, 2.49999997e-01, 2.45479080e-09, 2.60203117e-09,\n",
    "#         2.50000001e-01, 3.34751925e-10, 3.32148598e-10, 3.46652947e-10]),\n",
    "#  array([[4.5288696, 4.5337734, 3.711798 , 3.5188146],\n",
    "#         [4.813723 , 4.4849935, 3.7947109, 3.5508246],\n",
    "#         [4.6724405, 4.218369 , 3.5704765, 3.4494445],\n",
    "#         [4.0542464, 5.3404236, 4.6758094, 4.4132013]], dtype=float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06143844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The band gave a concert in Japan. \n",
      "\n",
      "The President greets the press in Chicago. \n",
      "\n",
      "{'band': 1, 'concert': 1, 'gave': 1, 'japan': 1} \n",
      "\n",
      "{'chicago': 1, 'greets': 1, 'president': 1, 'press': 1} \n",
      "\n",
      "['band' 'concert' 'gave' 'japan'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "['chicago' 'greets' 'president' 'press'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "embedding type being passed is : 1 \n",
      "\n",
      " global embedding type being passed is : 1 \n",
      "\n",
      "embedding type received by the find emb matrix is : 1 \n",
      "\n",
      "embd model type is : <class 'gensim.models.keyedvectors.KeyedVectors'> \n",
      "\n",
      "embd_model type changed to : <class 'gensim.models.keyedvectors.KeyedVectors'> \n",
      "\n",
      "(4, 300) sent1emb\n",
      "\n",
      " global embedding type being passed is : 1 \n",
      "\n",
      "embedding type received by the find emb matrix is : 1 \n",
      "\n",
      "embd model type is : <class 'gensim.models.keyedvectors.KeyedVectors'> \n",
      "\n",
      "embd_model type changed to : <class 'gensim.models.keyedvectors.KeyedVectors'> \n",
      "\n",
      "(4, 300) sent2emb\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "(4, 4) Dshape \n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "(8, 16) [[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]]\n",
      "Dshape: (16,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.883809542596161,\n",
       " array([3.48501400e-10, 1.65290340e-09, 2.49999999e-01, 8.68767734e-10,\n",
       "        3.28668785e-10, 3.40554971e-09, 8.32333805e-11, 2.49999998e-01,\n",
       "        3.36383594e-10, 2.49999997e-01, 2.45479080e-09, 2.60203117e-09,\n",
       "        2.50000001e-01, 3.34751925e-10, 3.32148598e-10, 3.46652947e-10]),\n",
       " array([[4.5288696, 4.5337734, 3.711798 , 3.5188146],\n",
       "        [4.813723 , 4.4849935, 3.7947109, 3.5508246],\n",
       "        [4.6724405, 4.218369 , 3.5704765, 3.4494445],\n",
       "        [4.0542464, 5.3404236, 4.6758094, 4.4132013]], dtype=float32))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Just retrying with modified code aimed at making it faster:\n",
    "\n",
    "model2 = WMD(sent3,sent2,1)\n",
    "diss2,t2,t2distancematrix = model2.word_mover_distance()\n",
    "diss2,t2,t2distancematrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5b51efe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The President greets the press in Chicago. \n",
      "\n",
      "Obama speaks to the media in Illinois. \n",
      "\n",
      "{'chicago': 1, 'greets': 1, 'president': 1, 'press': 1} \n",
      "\n",
      "{'illinois': 1, 'media': 1, 'obama': 1, 'speaks': 1} \n",
      "\n",
      "['chicago' 'greets' 'president' 'press'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "['illinois' 'media' 'obama' 'speaks'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "(4, 300) sent1emb\n",
      "\n",
      "(4, 300) sent2emb\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "(4, 4) Dshape \n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "(8, 16) [[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]]\n",
      "Dshape: (16,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.3741232173489397,\n",
       " array([2.50000000e-01, 4.70799925e-12, 6.85028414e-11, 5.34553639e-12,\n",
       "        3.18531061e-11, 1.81424167e-11, 3.21133748e-11, 2.50000000e-01,\n",
       "        2.14181898e-11, 5.88325714e-11, 2.50000000e-01, 4.78522987e-11,\n",
       "        2.52854272e-11, 2.50000000e-01, 2.74869074e-11, 2.89106866e-11]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = WMD(sent2,sent1,1)\n",
    "diss3,t3 = model3.word_mover_distance()\n",
    "diss3,t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "50bd7a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The President greets the press in Chicago. \n",
      "\n",
      "The band gave a concert in Japan. \n",
      "\n",
      "{'chicago': 1, 'greets': 1, 'president': 1, 'press': 1} \n",
      "\n",
      "{'band': 1, 'concert': 1, 'gave': 1, 'japan': 1} \n",
      "\n",
      "['chicago' 'greets' 'president' 'press'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "['band' 'concert' 'gave' 'japan'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "(4, 300) sent1emb\n",
      "\n",
      "(4, 300) sent2emb\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "(4, 4) Dshape \n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "(8, 16) [[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]]\n",
      "Dshape: (16,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.883809542596191,\n",
       " array([3.48500876e-10, 3.28668429e-10, 3.36383262e-10, 2.50000001e-01,\n",
       "        1.65290346e-09, 3.40554969e-09, 2.49999997e-01, 3.34752324e-10,\n",
       "        2.49999999e-01, 8.32333712e-11, 2.45479057e-09, 3.32148980e-10,\n",
       "        8.68768132e-10, 2.49999998e-01, 2.60203119e-09, 3.46653379e-10]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = WMD(sent2,sent3,1)\n",
    "diss4,t4 = model4.word_mover_distance()\n",
    "diss4,t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ddc3e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama speaks to the media in Illinois. \n",
      "\n",
      "The band gave a concert in Japan. \n",
      "\n",
      "{'illinois': 1, 'media': 1, 'obama': 1, 'speaks': 1} \n",
      "\n",
      "{'band': 1, 'concert': 1, 'gave': 1, 'japan': 1} \n",
      "\n",
      "['illinois' 'media' 'obama' 'speaks'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "['band' 'concert' 'gave' 'japan'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "(4, 300) sent1emb\n",
      "\n",
      "(4, 300) sent2emb\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "(4, 4) Dshape \n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "(8, 16) [[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]]\n",
      "Dshape: (16,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.9959894418802078,\n",
       " array([2.50000000e-01, 4.91648393e-13, 1.25024155e-13, 5.08493061e-13,\n",
       "        7.17848100e-13, 2.50000000e-01, 4.95096865e-15, 6.11554198e-14,\n",
       "        2.56308321e-13, 2.52526604e-13, 1.13908655e-13, 2.50000000e-01,\n",
       "        1.51104141e-13, 4.01038173e-14, 2.50000000e-01, 5.26588932e-14]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = WMD(sent1,sent3,1)\n",
    "diss5,t5 = model5.word_mover_distance()\n",
    "diss5,t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50301c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "[2.50000000e-01, 3.03720784e-11, 1.86845495e-11, 1.87096356e-11,\n",
    "        1.25400619e-11, 6.25733973e-10, 1.24664083e-11, 2.49999999e-01,\n",
    "        2.33762480e-11, 1.92005097e-11, 2.50000000e-01, 5.69153838e-13,\n",
    "        3.18499400e-11, 2.49999999e-01, 1.19951772e-11, 6.31456647e-10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1e795fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The band gave a concert in Japan. \n",
      "\n",
      "Obama speaks to the media in Illinois. \n",
      "\n",
      "{'illinois': 1, 'media': 1, 'obama': 1, 'speaks': 1} \n",
      "\n",
      "{'band': 1, 'concert': 1, 'gave': 1, 'japan': 1} \n",
      "\n",
      "['illinois' 'media' 'obama' 'speaks'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "['band' 'concert' 'gave' 'japan'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "(4, 300) sent1emb\n",
      "\n",
      "(4, 300) sent2emb\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "(4, 4) Dshape \n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "(8, 16) [[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]]\n",
      "Dshape: (16,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.9959894418802078,\n",
       " array([2.50000000e-01, 4.91648393e-13, 1.25024155e-13, 5.08493061e-13,\n",
       "        7.17848100e-13, 2.50000000e-01, 4.95096865e-15, 6.11554198e-14,\n",
       "        2.56308321e-13, 2.52526604e-13, 1.13908655e-13, 2.50000000e-01,\n",
       "        1.51104141e-13, 4.01038173e-14, 2.50000000e-01, 5.26588932e-14]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = WMD(sent3,sent1,1)\n",
    "diss6,t6 = model5.word_mover_distance()\n",
    "diss6,t6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ab0ddb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama speaks to the media in Illinois. \n",
      "\n",
      "The band gave a concert in Japan. \n",
      "\n",
      "{'illinois': 1, 'media': 1, 'obama': 1, 'speaks': 1} \n",
      "\n",
      "{'band': 1, 'concert': 1, 'gave': 1, 'japan': 1} \n",
      "\n",
      "['illinois' 'media' 'obama' 'speaks'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "['band' 'concert' 'gave' 'japan'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "(4, 300) sent1emb\n",
      "\n",
      "(4, 300) sent2emb\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "(4, 4) Dshape \n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "(8, 16) [[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]]\n",
      "Dshape: (16,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8.413724306355522,\n",
       " array([2.50000000e-01, 3.03720784e-11, 1.86845495e-11, 1.87096356e-11,\n",
       "        1.25400619e-11, 6.25733973e-10, 1.24664083e-11, 2.49999999e-01,\n",
       "        2.33762480e-11, 1.92005097e-11, 2.50000000e-01, 5.69153838e-13,\n",
       "        3.18499400e-11, 2.49999999e-01, 1.19951772e-11, 6.31456647e-10]),\n",
       " array([[8.9826   , 9.047554 , 7.807904 , 9.878976 ],\n",
       "        [8.741273 , 8.166015 , 6.9354115, 8.927074 ],\n",
       "        [9.665114 , 9.106033 , 7.3337817, 9.572257 ],\n",
       "        [8.857818 , 8.411441 , 7.132688 , 9.221346 ]], dtype=float32))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using glove now\n",
    "\n",
    "glovemodel1 = WMD(sent1,sent3,3)\n",
    "glovediss1,glovet1,dmat13 = glovemodel1.word_mover_distance()\n",
    "glovediss1,glovet1,dmat13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "61a89578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama speaks to the media in Illinois. \n",
      "\n",
      "The President greets the press in Chicago. \n",
      "\n",
      "{'illinois': 1, 'media': 1, 'obama': 1, 'speaks': 1} \n",
      "\n",
      "{'chicago': 1, 'greets': 1, 'president': 1, 'press': 1} \n",
      "\n",
      "['illinois' 'media' 'obama' 'speaks'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "['chicago' 'greets' 'president' 'press'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "(4, 300) sent1emb\n",
      "\n",
      "(4, 300) sent2emb\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "(4, 4) Dshape \n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "(8, 16) [[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]]\n",
      "Dshape: (16,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.713788986251661,\n",
       " array([2.50000000e-01, 2.22835912e-13, 2.78691205e-13, 9.45355661e-14,\n",
       "        1.53777156e-13, 2.07076598e-13, 2.18497826e-13, 2.50000000e-01,\n",
       "        2.46322668e-13, 2.32627133e-14, 2.50000000e-01, 2.30461774e-13,\n",
       "        1.95720392e-13, 2.50000000e-01, 3.09153046e-15, 2.54647804e-13]),\n",
       " array([[6.490648 , 9.131097 , 9.054297 , 8.658126 ],\n",
       "        [8.138092 , 8.493923 , 8.3068075, 5.7176623],\n",
       "        [8.488325 , 8.662736 , 7.8315964, 8.067997 ],\n",
       "        [8.160118 , 6.8152494, 8.358283 , 7.697754 ]], dtype=float32))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using glove now\n",
    "\n",
    "glovemodel2 = WMD(sent1,sent2,3)\n",
    "glovediss2,glovet2,Dmatx = glovemodel2.word_mover_distance()\n",
    "glovediss2,glovet2,Dmatx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5e89f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To check performance with normalisation later.\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "  \n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
    "  \n",
    "# a denotes adjective in \"pos\"\n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d56eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(a,b):\n",
    "    print('function called')\n",
    "    return a*b\n",
    "\n",
    "class Test:\n",
    "    \n",
    "    def __init__(self,a,b):\n",
    "        print(test(a,b))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "186c820e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function called\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "testobj = Test(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93551f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import os\n",
    "os.path.exists(\"../test/glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7406680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boy': 1, 'good': 3}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ' I am a good boy good good'\n",
    "\n",
    "#list11 = sentence_preprocess(sent)\n",
    "#list11.sort()\n",
    "\n",
    "count_dict = defaultdict(int)\n",
    "\n",
    "for word in sorted(sentence_preprocess(sent)):\n",
    "    count_dict[word] += 1\n",
    "    \n",
    "dict(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2554bfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2,\n",
       " 'b': 2,\n",
       " 'c': 1,\n",
       " 'd': 1,\n",
       " 'e': 3,\n",
       " 'f': 1,\n",
       " 'g': 1,\n",
       " 'h': 1,\n",
       " 'j': 1,\n",
       " 'v': 1}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e754c0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([2, 2, 1, 1, 3, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec783702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25, 0.75])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(list(count_dict.values()))\n",
    "a/np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94ad39e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "167ddcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = defaultdict(lambda:np.zeros(300))\n",
    "with open(f\"../test/glove.6B.300d.txt\",'r') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba78d307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.166015"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obama = embeddings_dict['media']\n",
    "president = embeddings_dict['concert']\n",
    "eucdist = np.linalg.norm(president-obama)\n",
    "eucdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4e4d8d",
   "metadata": {},
   "source": [
    "## Preprocessing bbc sport raw file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bcd2c615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"../test/bbcsport/athletics\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea5b0b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"../test/bbcsport/rugby\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75ebfaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"../test/bbcsport/cricket\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab104aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['README.TXT', 'rugby', 'athletics', 'tennis', 'cricket', 'football']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../test/bbcsport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f5a27f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"../test/bbcsport/football\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e34e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "248e4052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../test/bbcsport/rugby',\n",
       " '../test/bbcsport/athletics',\n",
       " '../test/bbcsport/tennis',\n",
       " '../test/bbcsport/cricket',\n",
       " '../test/bbcsport/football']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports_path = glob.glob(\"../test/bbcsport/*\")\n",
    "sports_path.pop(0)\n",
    "sports_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cbb54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "06200f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../test/bbcsport/', 'rugby')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"../test/bbcsport/rugby\"\n",
    "print(len(string))\n",
    "name = re.match('(../test/bbcsport/)(\\w*)',string)\n",
    "name.groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ed9bf6",
   "metadata": {},
   "source": [
    "### Note here: How to handle such files:\n",
    "\n",
    "with open open() function returns a file object. And for file object, there is no method like splitlines() or split(). You could use dir(f) to see all the methods of file object. _ioTextwrapper object. \n",
    "\n",
    "the following things will have following op:\n",
    "\n",
    "path = \"text_file_path.txt\"\n",
    "for txt in path:\n",
    "    with open ( path, \"r\") as f :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "545fc936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['188.txt',\n",
       " '003.txt',\n",
       " '153.txt',\n",
       " '217.txt',\n",
       " '027.txt',\n",
       " '031.txt',\n",
       " '161.txt',\n",
       " '143.txt',\n",
       " '112.txt',\n",
       " '126.txt',\n",
       " '104.txt',\n",
       " '167.txt',\n",
       " '195.txt',\n",
       " '237.txt',\n",
       " '223.txt',\n",
       " '141.txt',\n",
       " '086.txt',\n",
       " '262.txt',\n",
       " '109.txt',\n",
       " '226.txt',\n",
       " '091.txt',\n",
       " '106.txt',\n",
       " '148.txt',\n",
       " '001.txt',\n",
       " '002.txt',\n",
       " '046.txt',\n",
       " '227.txt',\n",
       " '193.txt',\n",
       " '197.txt',\n",
       " '119.txt',\n",
       " '243.txt',\n",
       " '151.txt',\n",
       " '258.txt',\n",
       " '127.txt',\n",
       " '245.txt',\n",
       " '220.txt',\n",
       " '010.txt',\n",
       " '057.txt',\n",
       " '162.txt',\n",
       " '207.txt',\n",
       " '133.txt',\n",
       " '087.txt',\n",
       " '192.txt',\n",
       " '150.txt',\n",
       " '103.txt',\n",
       " '210.txt',\n",
       " '168.txt',\n",
       " '121.txt',\n",
       " '231.txt',\n",
       " '017.txt',\n",
       " '125.txt',\n",
       " '194.txt',\n",
       " '248.txt',\n",
       " '117.txt',\n",
       " '068.txt',\n",
       " '191.txt',\n",
       " '131.txt',\n",
       " '081.txt',\n",
       " '171.txt',\n",
       " '169.txt',\n",
       " '019.txt',\n",
       " '174.txt',\n",
       " '085.txt',\n",
       " '241.txt',\n",
       " '145.txt',\n",
       " '030.txt',\n",
       " '149.txt',\n",
       " '101.txt',\n",
       " '094.txt',\n",
       " '242.txt',\n",
       " '206.txt',\n",
       " '042.txt',\n",
       " '128.txt',\n",
       " '093.txt',\n",
       " '115.txt',\n",
       " '190.txt',\n",
       " '014.txt',\n",
       " '043.txt',\n",
       " '154.txt',\n",
       " '107.txt',\n",
       " '203.txt',\n",
       " '216.txt',\n",
       " '113.txt',\n",
       " '234.txt',\n",
       " '229.txt',\n",
       " '118.txt',\n",
       " '247.txt',\n",
       " '183.txt',\n",
       " '090.txt',\n",
       " '011.txt',\n",
       " '054.txt',\n",
       " '029.txt',\n",
       " '047.txt',\n",
       " '156.txt',\n",
       " '246.txt',\n",
       " '235.txt',\n",
       " '080.txt',\n",
       " '036.txt',\n",
       " '182.txt',\n",
       " '096.txt',\n",
       " '065.txt',\n",
       " '025.txt',\n",
       " '061.txt',\n",
       " '249.txt',\n",
       " '077.txt',\n",
       " '058.txt',\n",
       " '116.txt',\n",
       " '186.txt',\n",
       " '045.txt',\n",
       " '095.txt',\n",
       " '076.txt',\n",
       " '180.txt',\n",
       " '251.txt',\n",
       " '238.txt',\n",
       " '120.txt',\n",
       " '160.txt',\n",
       " '147.txt',\n",
       " '176.txt',\n",
       " '257.txt',\n",
       " '261.txt',\n",
       " '139.txt',\n",
       " '098.txt',\n",
       " '184.txt',\n",
       " '124.txt',\n",
       " '253.txt',\n",
       " '172.txt',\n",
       " '082.txt',\n",
       " '219.txt',\n",
       " '232.txt',\n",
       " '132.txt',\n",
       " '041.txt',\n",
       " '039.txt',\n",
       " '097.txt',\n",
       " '013.txt',\n",
       " '233.txt',\n",
       " '208.txt',\n",
       " '129.txt',\n",
       " '202.txt',\n",
       " '264.txt',\n",
       " '064.txt',\n",
       " '026.txt',\n",
       " '020.txt',\n",
       " '092.txt',\n",
       " '049.txt',\n",
       " '111.txt',\n",
       " '099.txt',\n",
       " '102.txt',\n",
       " '059.txt',\n",
       " '263.txt',\n",
       " '211.txt',\n",
       " '067.txt',\n",
       " '254.txt',\n",
       " '052.txt',\n",
       " '108.txt',\n",
       " '240.txt',\n",
       " '250.txt',\n",
       " '035.txt',\n",
       " '009.txt',\n",
       " '205.txt',\n",
       " '144.txt',\n",
       " '252.txt',\n",
       " '213.txt',\n",
       " '244.txt',\n",
       " '023.txt',\n",
       " '175.txt',\n",
       " '024.txt',\n",
       " '166.txt',\n",
       " '028.txt',\n",
       " '173.txt',\n",
       " '178.txt',\n",
       " '100.txt',\n",
       " '079.txt',\n",
       " '130.txt',\n",
       " '265.txt',\n",
       " '159.txt',\n",
       " '189.txt',\n",
       " '152.txt',\n",
       " '032.txt',\n",
       " '034.txt',\n",
       " '016.txt',\n",
       " '158.txt',\n",
       " '196.txt',\n",
       " '260.txt',\n",
       " '114.txt',\n",
       " '204.txt',\n",
       " '239.txt',\n",
       " '137.txt',\n",
       " '053.txt',\n",
       " '022.txt',\n",
       " '075.txt',\n",
       " '005.txt',\n",
       " '215.txt',\n",
       " '256.txt',\n",
       " '048.txt',\n",
       " '218.txt',\n",
       " '255.txt',\n",
       " '055.txt',\n",
       " '134.txt',\n",
       " '110.txt',\n",
       " '199.txt',\n",
       " '084.txt',\n",
       " '212.txt',\n",
       " '040.txt',\n",
       " '012.txt',\n",
       " '140.txt',\n",
       " '071.txt',\n",
       " '050.txt',\n",
       " '201.txt',\n",
       " '122.txt',\n",
       " '056.txt',\n",
       " '105.txt',\n",
       " '066.txt',\n",
       " '033.txt',\n",
       " '135.txt',\n",
       " '074.txt',\n",
       " '214.txt',\n",
       " '073.txt',\n",
       " '209.txt',\n",
       " '088.txt',\n",
       " '187.txt',\n",
       " '051.txt',\n",
       " '181.txt',\n",
       " '177.txt',\n",
       " '228.txt',\n",
       " '069.txt',\n",
       " '236.txt',\n",
       " '004.txt',\n",
       " '225.txt',\n",
       " '163.txt',\n",
       " '037.txt',\n",
       " '146.txt',\n",
       " '222.txt',\n",
       " '021.txt',\n",
       " '060.txt',\n",
       " '164.txt',\n",
       " '006.txt',\n",
       " '072.txt',\n",
       " '170.txt',\n",
       " '155.txt',\n",
       " '157.txt',\n",
       " '044.txt',\n",
       " '230.txt',\n",
       " '089.txt',\n",
       " '221.txt',\n",
       " '165.txt',\n",
       " '008.txt',\n",
       " '018.txt',\n",
       " '200.txt',\n",
       " '078.txt',\n",
       " '070.txt',\n",
       " '224.txt',\n",
       " '185.txt',\n",
       " '198.txt',\n",
       " '038.txt',\n",
       " '138.txt',\n",
       " '015.txt',\n",
       " '123.txt',\n",
       " '136.txt',\n",
       " '083.txt',\n",
       " '062.txt',\n",
       " '142.txt',\n",
       " '007.txt',\n",
       " '179.txt',\n",
       " '063.txt',\n",
       " '259.txt']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = os.listdir(\"../test/bbcsport/football/\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4bc67095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moyes', 'beattie', 'dismissal', 'everton', 'manager', 'david', 'moyes', 'discipline', 'striker', 'james', 'beattie', 'headbutt', 'chelsea', 'defender', 'william', 'gallas', 'scot', 'initially', 'defended', 'beattie', 'whose', 'dismissal', 'put', 'everton', 'back', 'foot', 'game', 'ultimately', 'lost', 'saying', 'gallas', 'overreacted', 'rethink', 'looking', 'video', 'evidence', 'said', 'believe', 'set', 'record', 'straight', 'conceding', 'dismissal', 'right', 'correct', 'moyes', 'added', 'comments', 'saturday', 'came', 'immediately', 'final', 'whistle', 'point', 'opportunity', 'see', 'one', 'quick', 'incident', 'club', 'website', 'also', 'reported', 'beattie', 'seemed', 'unrepentant', 'saturday', 'match', 'insisting', 'gallas', 'would', 'stayed', 'lot', 'longer', 'headbutted', 'apologised', 'moyes', 'continued', 'although', 'incident', 'totally', 'character', 'james', 'never', 'even', 'suspended', 'career', 'actions', 'unacceptable', 'detrimental', 'effect', 'james', 'issue', 'formal', 'apology', 'everton', 'supporters', 'immediately', 'game', 'right', 'thing', 'done', 'subjected', 'normal', 'club', 'discipline', 'competitive', 'player', 'fair', 'player', 'know', 'upset', 'happened', 'however', 'must', 'say', 'still', 'believe', 'chelsea', 'player', 'question', 'go', 'easily', 'speaking', 'immediately', 'game', 'moyes', 'said', 'think', 'time', 'would', 'ashamed', 'gone', 'easily', 'million', 'years', 'would', 'john', 'terry', 'gone', 'way', 'never', 'heard', 'anybody', 'butting', 'somebody', 'behind', 'running', 'happened', 'big', 'strong', 'thought', 'push', 'initially', 'still', 'think', 'angry', 'beattie', 'initially', 'said', 'gallas', 'would', 'stayed', 'lot', 'longer', 'headbutted', 'tell', 'intentional', 'headbutt', 'chasing', 'ball', 'corner', 'william', 'gallas', 'looking', 'shoulder', 'blocking', 'stopping', 'running', 'said', 'going', 'stay', 'way', 'go', 'straight', 'heads', 'barely', 'touched', 'intentional', 'headbutt']\n"
     ]
    }
   ],
   "source": [
    "d = os.listdir(\"../test/bbcsport/athletics/\")\n",
    "\n",
    "\n",
    "for txt in d:\n",
    "    with open(f\"../test/bbcsport/football/{txt}\", 'r') as f:\n",
    "        \n",
    "        lines = f.read()\n",
    "        preprocesedline = sentence_preprocess(lines)\n",
    "        print(preprocesedline)\n",
    "        \n",
    "        \n",
    "        #for line in f:\n",
    "            #print(line.split())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b851aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding = KeyedVectors.load('google300w2v.kv', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7c1265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_test = defaultdict(int)\n",
    "with open(f\"../test/glove.6B.300d.txt\",'r') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            glove_test[word] = vector\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "972be4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.38914  ,  0.54391  , -0.37051  ,  0.11197  ,  0.52875  ,\n",
       "       -0.48597  , -0.81167  , -0.49878  , -0.42569  ,  0.34979  ,\n",
       "       -0.59059  , -0.45513  , -0.12591  , -0.35044  , -0.33486  ,\n",
       "        0.1549   , -0.265    , -0.18403  , -0.086644 ,  0.32109  ,\n",
       "        0.68264  ,  0.38181  , -0.14069  , -0.30722  ,  0.26674  ,\n",
       "        0.081064 ,  0.10712  ,  0.48131  ,  0.022878 , -0.1875   ,\n",
       "        0.65655  , -0.43314  ,  0.71209  , -0.15094  , -0.44511  ,\n",
       "       -0.37371  , -0.17895  ,  0.3753   , -0.38329  ,  0.25674  ,\n",
       "        0.0017494, -0.20797  , -0.0259   ,  0.18894  , -0.044307 ,\n",
       "        0.58492  , -0.052792 , -0.0034005,  0.64318  , -0.31403  ,\n",
       "       -0.55783  , -0.33489  ,  0.13992  ,  0.28535  ,  0.025751 ,\n",
       "       -0.63934  ,  0.40252  , -0.18133  , -0.68885  ,  0.38223  ,\n",
       "       -0.16864  ,  0.048815 , -0.75052  , -0.26309  , -0.32622  ,\n",
       "       -0.079043 ,  0.56622  , -0.52637  ,  0.12174  ,  0.016791 ,\n",
       "       -0.60541  , -0.50993  ,  0.2132   ,  1.1645   ,  0.33784  ,\n",
       "        0.36417  ,  0.15283  ,  0.1829   , -0.099893 ,  0.082614 ,\n",
       "        0.17494  , -0.17438  ,  0.36613  , -0.65767  , -0.66161  ,\n",
       "       -1.3094   ,  0.52759  ,  0.044944 ,  0.42247  , -0.047235 ,\n",
       "       -0.037729 ,  0.57797  ,  0.6263   , -0.19985  , -0.49396  ,\n",
       "       -0.013854 ,  0.97052  , -0.54422  , -0.70697  ,  0.40026  ,\n",
       "       -0.16072  ,  0.097171 , -0.31398  ,  1.0856   , -0.8479   ,\n",
       "        0.32292  ,  0.43996  ,  0.64941  ,  0.40847  ,  0.63548  ,\n",
       "        0.090166 ,  0.42144  ,  0.17505  , -0.013707 , -0.22882  ,\n",
       "        0.053196 , -0.12392  ,  0.46966  , -0.35162  , -0.50774  ,\n",
       "       -0.3748   ,  0.084493 , -0.10247  ,  0.38833  ,  0.57629  ,\n",
       "        0.081802 , -0.87825  ,  0.23767  , -0.64107  ,  0.27285  ,\n",
       "       -0.042818 , -0.099305 , -0.26479  ,  0.42844  ,  0.47967  ,\n",
       "        0.014817 ,  0.32669  , -0.60157  , -0.24451  , -0.060611 ,\n",
       "       -0.82495  ,  0.61882  , -0.13991  , -0.46738  , -0.47415  ,\n",
       "        0.031184 ,  0.058759 ,  0.30651  ,  0.24348  , -0.41634  ,\n",
       "       -0.27668  , -0.58966  , -0.35362  ,  0.05039  ,  0.46452  ,\n",
       "       -0.47522  , -0.2273   , -0.59426  , -0.18192  , -0.21697  ,\n",
       "       -0.050105 ,  0.15867  ,  0.18481  , -0.74438  ,  0.2972   ,\n",
       "        0.10377  ,  0.03602  ,  0.19458  ,  0.1736   ,  0.093028 ,\n",
       "       -0.76354  ,  0.4506   , -0.23847  , -0.29358  ,  0.51277  ,\n",
       "        0.17104  , -0.11376  ,  0.019896 , -0.071454 ,  0.475    ,\n",
       "        0.32856  , -0.15853  ,  0.87592  ,  0.16832  , -0.48613  ,\n",
       "       -0.66415  , -0.32971  ,  0.039387 ,  0.52902  ,  0.45774  ,\n",
       "        0.085641 , -0.068959 ,  0.34047  ,  0.41842  , -1.0636   ,\n",
       "       -0.43556  ,  0.20823  ,  0.11705  , -0.06649  , -0.27844  ,\n",
       "        0.86333  ,  0.37094  , -0.1773   , -0.8628   , -0.64436  ,\n",
       "        0.21626  , -0.072283 ,  0.17023  , -0.61928  ,  0.15848  ,\n",
       "        0.43575  ,  0.25058  , -0.098125 , -0.30853  ,  0.25961  ,\n",
       "       -0.24072  , -0.17678  ,  0.011792 , -0.53606  ,  0.10503  ,\n",
       "        0.12688  ,  0.3439   , -0.027738 , -0.64698  ,  0.065037 ,\n",
       "        0.11107  , -0.035215 ,  0.27466  ,  0.52337  ,  0.50473  ,\n",
       "       -0.34616  ,  0.97855  ,  0.43592  ,  0.012513 ,  0.13943  ,\n",
       "        0.46443  , -0.15137  ,  0.56548  , -0.27055  , -0.17242  ,\n",
       "       -0.11086  , -0.18168  , -0.64656  ,  0.038983 ,  0.25374  ,\n",
       "        0.37266  ,  0.84367  ,  0.21968  ,  0.05933  ,  0.15661  ,\n",
       "       -0.27464  , -0.33244  , -0.20832  , -0.11329  , -0.10961  ,\n",
       "       -0.57889  , -0.71164  , -0.72587  , -0.2075   , -0.027288 ,\n",
       "        0.14707  ,  0.8881   ,  0.097882 ,  0.71199  , -0.70211  ,\n",
       "        0.15114  ,  0.015207 , -0.68571  ,  0.046973 , -0.18918  ,\n",
       "       -0.11035  , -0.23328  , -0.30916  ,  0.41304  ,  0.22864  ,\n",
       "       -0.17957  ,  0.28134  , -0.068614 , -0.48954  , -0.56667  ,\n",
       "       -0.11921  ,  0.07827  ,  0.73185  ,  0.46795  ,  0.65864  ,\n",
       "       -0.28984  , -0.093998 , -0.27828  , -0.3502   , -0.31768  ,\n",
       "       -0.12997  ,  0.38727  ,  0.49354  ,  0.2183   ,  0.10413  ,\n",
       "       -0.77634  , -0.066841 , -0.10727  ,  0.036533 , -0.50276  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_test['giggs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55ca9121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([-0.05004883,  0.01330566,  0.01586914,  0.13183594,  0.12255859,\n",
       "        -0.04589844,  0.01202393, -0.22363281,  0.00939941, -0.01116943,\n",
       "        -0.03881836, -0.00193787, -0.20507812, -0.04492188,  0.02355957,\n",
       "         0.20214844,  0.04223633,  0.15722656, -0.06982422, -0.08837891,\n",
       "        -0.13574219, -0.04003906,  0.26953125, -0.11132812,  0.00280762,\n",
       "         0.03955078, -0.09814453, -0.00674438,  0.06738281, -0.09228516,\n",
       "        -0.09619141,  0.13183594,  0.06494141, -0.11962891, -0.07910156,\n",
       "         0.171875  , -0.17382812,  0.09716797,  0.06298828,  0.14941406,\n",
       "         0.04711914, -0.17871094,  0.22851562, -0.05737305,  0.18554688,\n",
       "        -0.19921875,  0.14453125, -0.21191406,  0.03857422,  0.07617188,\n",
       "        -0.02514648, -0.01428223, -0.08789062, -0.06835938, -0.13671875,\n",
       "        -0.00415039, -0.03686523,  0.03686523, -0.05859375,  0.00527954,\n",
       "        -0.08642578,  0.16699219, -0.10107422, -0.1328125 ,  0.03222656,\n",
       "        -0.11328125, -0.04541016, -0.00263977,  0.06591797,  0.15136719,\n",
       "         0.07519531,  0.14257812, -0.05297852,  0.07080078, -0.25      ,\n",
       "        -0.07714844, -0.04223633, -0.03344727,  0.01422119, -0.14355469,\n",
       "        -0.09423828,  0.11621094, -0.1484375 , -0.05908203,  0.09619141,\n",
       "         0.03466797,  0.10205078,  0.1484375 ,  0.06201172, -0.00390625,\n",
       "        -0.04248047,  0.06835938, -0.12890625,  0.0279541 , -0.09765625,\n",
       "         0.06884766, -0.14160156, -0.05712891,  0.22167969, -0.03710938,\n",
       "        -0.08154297,  0.1328125 ,  0.08447266,  0.21582031,  0.05078125,\n",
       "         0.12402344,  0.02746582,  0.06591797,  0.08447266,  0.03442383,\n",
       "        -0.08203125, -0.05957031, -0.01483154,  0.00289917, -0.02575684,\n",
       "         0.03320312, -0.05200195, -0.10302734, -0.03564453, -0.03662109,\n",
       "        -0.07177734, -0.0703125 , -0.04370117,  0.12597656, -0.01544189,\n",
       "        -0.23632812, -0.21875   ,  0.15917969,  0.11767578, -0.0402832 ,\n",
       "        -0.08837891, -0.04003906,  0.06225586, -0.05444336, -0.09619141,\n",
       "        -0.01916504, -0.10693359,  0.08300781, -0.00300598,  0.03735352,\n",
       "         0.2421875 , -0.01403809,  0.18261719, -0.04272461,  0.0402832 ,\n",
       "        -0.04443359, -0.11035156, -0.00332642, -0.03930664, -0.13671875,\n",
       "         0.00494385, -0.18164062, -0.12890625, -0.00176239, -0.09521484,\n",
       "        -0.09228516, -0.02246094, -0.03112793, -0.04199219, -0.09423828,\n",
       "         0.15332031,  0.0625    ,  0.03540039, -0.01635742,  0.140625  ,\n",
       "        -0.16894531,  0.06298828, -0.00476074, -0.19628906,  0.03393555,\n",
       "        -0.24707031,  0.06787109, -0.11669922,  0.01501465,  0.00701904,\n",
       "         0.16308594,  0.20214844, -0.265625  ,  0.05737305, -0.15917969,\n",
       "        -0.09130859,  0.07226562,  0.09228516,  0.16015625,  0.00704956,\n",
       "         0.1640625 ,  0.04736328, -0.05053711,  0.05004883, -0.09521484,\n",
       "        -0.13085938, -0.00765991, -0.15527344, -0.02331543,  0.19824219,\n",
       "        -0.04394531, -0.05102539,  0.234375  , -0.17480469, -0.10302734,\n",
       "        -0.06542969, -0.08837891, -0.20019531, -0.171875  ,  0.08544922,\n",
       "        -0.1875    , -0.02453613, -0.10009766, -0.10839844,  0.10595703,\n",
       "         0.046875  , -0.05932617, -0.24707031, -0.02307129, -0.18652344,\n",
       "         0.04663086,  0.1171875 , -0.15722656, -0.17382812,  0.05834961,\n",
       "        -0.15039062, -0.05126953,  0.16308594,  0.08349609,  0.0703125 ,\n",
       "         0.05297852,  0.08789062, -0.0703125 ,  0.07470703, -0.08349609,\n",
       "        -0.13476562, -0.02856445,  0.07128906, -0.04907227,  0.01611328,\n",
       "         0.12060547, -0.15332031, -0.11572266,  0.0534668 ,  0.22363281,\n",
       "         0.07910156, -0.00656128,  0.08837891,  0.02697754, -0.24609375,\n",
       "         0.17089844, -0.23632812,  0.08105469, -0.18652344,  0.07470703,\n",
       "         0.08105469,  0.13574219,  0.16992188,  0.28320312,  0.18164062,\n",
       "        -0.16210938, -0.09716797,  0.0612793 , -0.08300781,  0.0300293 ,\n",
       "         0.10742188, -0.05053711,  0.10595703, -0.08447266, -0.06982422,\n",
       "        -0.01623535, -0.234375  , -0.07128906,  0.06689453, -0.07958984,\n",
       "        -0.18652344,  0.10644531, -0.02197266,  0.03344727,  0.00872803,\n",
       "        -0.07324219,  0.125     ,  0.01342773, -0.06884766,  0.13085938,\n",
       "        -0.10351562,  0.16308594,  0.03833008, -0.00628662, -0.11572266,\n",
       "        -0.00692749,  0.125     ,  0.06787109,  0.09716797, -0.02697754,\n",
       "         0.10009766,  0.15429688, -0.03100586,  0.04296875, -0.29101562,\n",
       "         0.00952148, -0.13183594,  0.04199219, -0.09765625,  0.10009766],\n",
       "       dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding['giggs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8efcadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['athletics','rugby','tennis','cricket','football']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a4fe008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['003.txt',\n",
       " '027.txt',\n",
       " '031.txt',\n",
       " '143.txt',\n",
       " '112.txt',\n",
       " '126.txt',\n",
       " '104.txt',\n",
       " '141.txt',\n",
       " '086.txt',\n",
       " '109.txt',\n",
       " '091.txt',\n",
       " '106.txt',\n",
       " '001.txt',\n",
       " '002.txt',\n",
       " '046.txt',\n",
       " '119.txt',\n",
       " '127.txt',\n",
       " '010.txt',\n",
       " '057.txt',\n",
       " '133.txt',\n",
       " '087.txt',\n",
       " '103.txt',\n",
       " '121.txt',\n",
       " '017.txt',\n",
       " '125.txt',\n",
       " '117.txt',\n",
       " '068.txt',\n",
       " '131.txt',\n",
       " '081.txt',\n",
       " '019.txt',\n",
       " '085.txt',\n",
       " '145.txt',\n",
       " '030.txt',\n",
       " '101.txt',\n",
       " '094.txt',\n",
       " '042.txt',\n",
       " '128.txt',\n",
       " '093.txt',\n",
       " '115.txt',\n",
       " '014.txt',\n",
       " '043.txt',\n",
       " '107.txt',\n",
       " '113.txt',\n",
       " '118.txt',\n",
       " '090.txt',\n",
       " '011.txt',\n",
       " '054.txt',\n",
       " '029.txt',\n",
       " '047.txt',\n",
       " '080.txt',\n",
       " '036.txt',\n",
       " '096.txt',\n",
       " '065.txt',\n",
       " '025.txt',\n",
       " '061.txt',\n",
       " '077.txt',\n",
       " '058.txt',\n",
       " '116.txt',\n",
       " '045.txt',\n",
       " '095.txt',\n",
       " '076.txt',\n",
       " '120.txt',\n",
       " '147.txt',\n",
       " '139.txt',\n",
       " '098.txt',\n",
       " '124.txt',\n",
       " '082.txt',\n",
       " '132.txt',\n",
       " '041.txt',\n",
       " '039.txt',\n",
       " '097.txt',\n",
       " '013.txt',\n",
       " '129.txt',\n",
       " '064.txt',\n",
       " '026.txt',\n",
       " '020.txt',\n",
       " '092.txt',\n",
       " '049.txt',\n",
       " '111.txt',\n",
       " '099.txt',\n",
       " '102.txt',\n",
       " '059.txt',\n",
       " '067.txt',\n",
       " '052.txt',\n",
       " '108.txt',\n",
       " '035.txt',\n",
       " '009.txt',\n",
       " '144.txt',\n",
       " '023.txt',\n",
       " '024.txt',\n",
       " '028.txt',\n",
       " '100.txt',\n",
       " '079.txt',\n",
       " '130.txt',\n",
       " '032.txt',\n",
       " '034.txt',\n",
       " '016.txt',\n",
       " '114.txt',\n",
       " '137.txt',\n",
       " '053.txt',\n",
       " '022.txt',\n",
       " '075.txt',\n",
       " '005.txt',\n",
       " '048.txt',\n",
       " '055.txt',\n",
       " '134.txt',\n",
       " '110.txt',\n",
       " '084.txt',\n",
       " '040.txt',\n",
       " '012.txt',\n",
       " '140.txt',\n",
       " '071.txt',\n",
       " '050.txt',\n",
       " '122.txt',\n",
       " '056.txt',\n",
       " '105.txt',\n",
       " '066.txt',\n",
       " '033.txt',\n",
       " '135.txt',\n",
       " '074.txt',\n",
       " '073.txt',\n",
       " '088.txt',\n",
       " '051.txt',\n",
       " '069.txt',\n",
       " '004.txt',\n",
       " '037.txt',\n",
       " '146.txt',\n",
       " '021.txt',\n",
       " '060.txt',\n",
       " '006.txt',\n",
       " '072.txt',\n",
       " '044.txt',\n",
       " '089.txt',\n",
       " '008.txt',\n",
       " '018.txt',\n",
       " '078.txt',\n",
       " '070.txt',\n",
       " '038.txt',\n",
       " '138.txt',\n",
       " '015.txt',\n",
       " '123.txt',\n",
       " '136.txt',\n",
       " '083.txt',\n",
       " '062.txt',\n",
       " '142.txt',\n",
       " '007.txt',\n",
       " '063.txt']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../test/bbcsport/rugby\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63895ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Important Important Important, handling file.\n",
    "\n",
    "# I created a dictionary named bbcsport_dataset, then stored it using json, and now read\n",
    "# that into system as loaded_bbcdataset.\n",
    "\n",
    "\n",
    "categories = ['athletics','rugby','tennis','cricket','football']\n",
    "\n",
    "bbcsport_dataset = {}\n",
    "\n",
    "main_path = \"../test/bbcsport/\"\n",
    "\n",
    "i = 1\n",
    "\n",
    "for category in categories:\n",
    "    category_path = main_path+category # \"../test/bbcsport/category\", go to each category, make a list of \n",
    "    elements_incategory = os.listdir(category_path) #path of all the text files in that category folder.\n",
    "    print(category)\n",
    "    \n",
    "    for element in elements_incategory: #read each file one by one and store the sentence string in dictionary.\n",
    "            \n",
    "            #print(i)\n",
    "            #i+= 1\n",
    "            with open(f\"../test/bbcsport/{category}/{element}\", encoding=\"utf8\", errors='ignore') as f:\n",
    "            \n",
    "                lines = f.read()\n",
    "                #lines.decode(\"utf-8\")\n",
    "            \n",
    "            try:\n",
    "                print(bbcsport_dataset[category])\n",
    "            \n",
    "            except KeyError:\n",
    "                #print('triggered')\n",
    "                bbcsport_dataset[category] = []\n",
    "            \n",
    "            bbcsport_dataset[category].append(lines) \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c29de29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Real will finish abandoned match\\n\\nReal Madrid and Real Socieded will play the final six minutes of their match, which was abandoned on Sunday because of a bomb scare.\\n\\nThe Bernabeu was evacuated with the score at 1-1 and two minutes of normal time remaining in the game. The teams will now play the final two minutes, plus four minutes of injury time, on 5 January. Brazilian Ronaldo and England captain David Beckham had to wait in the street in their kit after the abandonment. Real Sociedad president Jose Luis Astiazaran said: \"We thought the best thing was to play the time remaining.\"\\n\\nHundreds of fans streamed across the pitch on their way to the exits after the game was called off. Tourists and fans took advantage of the opportunity for a photograph between the famous stadium\\'s goalposts. The two clubs met the Spanish FA on Monday and Astiazaran added: \"We thought about giving the game as concluded but after talking with the FA we decided there was no precedent for that and the best thing was to play the time that was remaining.\" Real Madrid director of sport Emilio Butragueno praised the spectators inside the ground for their conduct. \"I\\'d like to highlight the behaviour of the fans, who showed great maturity and it was an example of good citizenship,\" he said. Butragueno confirned, before confirming that Tuesday\\'s charity match - which has been billed as \"Ronaldo\\'s friends against Zidane\\'s friends\" - will go ahead as planned. \"I\\'d also like to take the chance to say that tomorrow\\'s game will take place,\" Butragueno declared of the \"Partido contra la Pobreza\" (Game Against Poverty). He added: \"Football is important for society and we want to show that. \"We also think that football should be a fiesta, we had programmed and people deserve to enjoy the game.\"\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbcsport_dataset['football'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a67e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## will enter path one by one, create a dictionary which will have different articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37548df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import json\n",
    "\n",
    "\n",
    "a_file = open(\"bbcsport_dataset.json\", \"w\")\n",
    "json.dump(bbcsport_dataset, a_file)\n",
    "a_file.close()\n",
    "'''\n",
    "# a_file = open(\"data.json\", \"r\")\n",
    "# output = a_file.read()\n",
    "# print(output)\n",
    "\n",
    "# a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b939070e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1453351\n"
     ]
    }
   ],
   "source": [
    "### IMPORTANT : to store and read file as dictionary string\n",
    "'''\n",
    "a_file = open(\"bbcsport_dataset.json\", \"r\")\n",
    "output = a_file.read()\n",
    "print(len(output))\n",
    "\n",
    "a_file.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b769a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TO LOAD as DICTIONARY\n",
    "\n",
    "import json\n",
    "file = open(\"bbcsport_dataset.json\",\"r\")\n",
    "loaded_bbcdataset = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9e5bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bitter Santini hits out at Spurs\\n\\nFormer Tottenham coach Jacques Santini said he quit partly because he felt agreements with the club were broken.\\n\\nSantini, 52, left in November after just 13 games in charge amid tensions with sporting director Frank Arnesen. \"They promised me a big apartment on the beach and I found myself 200m from the sea with a view of my neighbours,\" he told France\\'s Journal di Dimanche. But the ex-France coach admitted he \"dug his own grave\" by agreeing to join the club before the end of Euro 2004. \"My only regret is having signed too early (for Tottenham). I should have waited until after Euro 2004 even if that means I might have missed my chance,\" he said. Santini also said he was not given enough information about Spurs\\' transfer policy. \"I learned on the day of our team photo that our captain (Stephen Carr) was leaving the club,\" he said.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_bbcdataset['football'][3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "514bc834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WMD_MAX experimentation.ipynb',\n",
       " 'data.json',\n",
       " '.ipynb_checkpoints',\n",
       " 'glove.6B.100d.txt',\n",
       " 'wmd.ipynb',\n",
       " 'google300w2v.kv',\n",
       " 'glove.6B.200d.txt',\n",
       " 'model.npy',\n",
       " 'glove.6B.300d.txt',\n",
       " 'glove.6B.zip',\n",
       " 'Miniconda3-latest-Linux-x86_64.sh',\n",
       " 'google300w2v.kv.vectors.npy',\n",
       " 'Untitled.ipynb',\n",
       " 'glove.6B.50d.txt',\n",
       " 'model.npz',\n",
       " 'test_first_jupyteronada.ipynb',\n",
       " 'bbcsport',\n",
       " 'totestsavedmodel.ipynb']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c48a8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triggered\n"
     ]
    }
   ],
   "source": [
    "newdict = {}\n",
    "\n",
    "try:\n",
    "    newdict['category']\n",
    "    print['error']\n",
    "except KeyError:\n",
    "    print('triggered')\n",
    "    newdict['category'] = []\n",
    "    \n",
    "    \n",
    "newdict['category'].append('hey hey')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9ccd49f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': ['hey hey', 'hello']}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdict['category'].append('hello')\n",
    "newdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9df779d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Relaxed WMD : both min and max.\n",
    "\n",
    "a = np.arange(9).reshape(3,3)\n",
    "a\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a44f557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.T.min(axis=1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "563839a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = [0.5,0.25,0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42492383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.25"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.dot(b,pi)\n",
    "d = np.dot(a.min(axis =1),pi)\n",
    "max(c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a01c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying with the new code of min max and normal and relaxed:\n",
    "\n",
    "sent1 = \"Obama speaks to the media in Illinois.\"\n",
    "sent2 = \"The President greets the press in Chicago.\"\n",
    "sent3 = \"The band gave a concert in Japan.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "77e9d0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama speaks to the media in Illinois. \n",
      "\n",
      "The President greets the press in Chicago. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "modeltest = WMD(sent1,sent2,1,cost='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1849fe00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'illinois': 1, 'media': 1, 'obama': 1, 'speaks': 1} \n",
      "\n",
      "{'chicago': 1, 'greets': 1, 'president': 1, 'press': 1} \n",
      "\n",
      "['illinois' 'media' 'obama' 'speaks'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "['chicago' 'greets' 'president' 'press'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "embedding type being passed is : 1 \n",
      "\n",
      " global embedding type being passed is : 1 \n",
      "\n",
      "embedding type received by the find emb matrix is : 1 \n",
      "\n",
      "embd model type is : <class 'gensim.models.keyedvectors.KeyedVectors'> \n",
      "\n",
      "embd_model type changed to : <class 'gensim.models.keyedvectors.KeyedVectors'> \n",
      "\n",
      "(4, 300) sent1emb\n",
      "\n",
      " global embedding type being passed is : 1 \n",
      "\n",
      "embedding type received by the find emb matrix is : 1 \n",
      "\n",
      "embd model type is : <class 'gensim.models.keyedvectors.KeyedVectors'> \n",
      "\n",
      "embd_model type changed to : <class 'gensim.models.keyedvectors.KeyedVectors'> \n",
      "\n",
      "(4, 300) sent2emb\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "(4, 4) Dshape \n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "Dshape, len pi till here : (4, 4) 4 \n",
      "\n",
      "A.shape (4, 4) \n",
      "\n",
      "[array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "      dtype=float32)] Aeq\n",
      "\n",
      "(8, 16) [[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.3741232173489615,\n",
       " array([2.50000000e-01, 3.18531834e-11, 2.14184326e-11, 2.52857048e-11,\n",
       "        4.70801233e-12, 1.81424091e-11, 5.88324554e-11, 2.50000000e-01,\n",
       "        6.85027770e-11, 3.21133789e-11, 2.50000000e-01, 2.74871660e-11,\n",
       "        5.34556353e-12, 2.50000000e-01, 4.78527543e-11, 2.89110126e-11]),\n",
       " array([[3.169699 , 4.937704 , 4.357834 , 4.119726 ],\n",
       "        [4.4567947, 4.215941 , 3.366701 , 2.1343176],\n",
       "        [4.0367475, 5.5453153, 4.782619 , 4.6934934],\n",
       "        [4.7602735, 3.4098573, 3.7898932, 3.376263 ]], dtype=float32))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diss,t,matx = modeltest.word_mover_distance()\n",
    "diss,t,matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b22883a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama speaks to the media in Illinois. \n",
      "\n",
      "The President greets the press in Chicago. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = WMD(sent1,sent2,1,wmd_type='relaxed',cost='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c3e75ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'illinois': 1, 'media': 1, 'obama': 1, 'speaks': 1} \n",
      "\n",
      "{'chicago': 1, 'greets': 1, 'president': 1, 'press': 1} \n",
      "\n",
      "['illinois' 'media' 'obama' 'speaks'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "['chicago' 'greets' 'president' 'press'] \n",
      "\n",
      "[1 1 1 1] \n",
      "\n",
      "embedding type being passed is : 1 \n",
      "\n",
      " global embedding type being passed is : 1 \n",
      "\n",
      "embedding type received by the find emb matrix is : 1 \n",
      "\n",
      "embd model type is : <class 'gensim.models.keyedvectors.KeyedVectors'> \n",
      "\n",
      "embd_model type changed to : <class 'gensim.models.keyedvectors.KeyedVectors'> \n",
      "\n",
      "(4, 300) sent1emb\n",
      "\n",
      " global embedding type being passed is : 1 \n",
      "\n",
      "embedding type received by the find emb matrix is : 1 \n",
      "\n",
      "embd model type is : <class 'gensim.models.keyedvectors.KeyedVectors'> \n",
      "\n",
      "embd_model type changed to : <class 'gensim.models.keyedvectors.KeyedVectors'> \n",
      "\n",
      "(4, 300) sent2emb\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "[0.25 0.25 0.25 0.25] self.pi\n",
      "\n",
      "(4, 4) Dshape \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1792567372322083"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diss_relaxed = model2.word_mover_distance()\n",
    "diss_relaxed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490e3b2b",
   "metadata": {},
   "source": [
    "## WORKED JUST PERFECTLY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03341a07",
   "metadata": {},
   "source": [
    "### Splitting dictionary into arrays and making training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5dff7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbcsport_sentences = []\n",
    "\n",
    "bbcsport_labels= []\n",
    "\n",
    "for key in loaded_bbcdataset.keys():\n",
    "    bbcsport_sentences.extend(loaded_bbcdataset[key])\n",
    "    bbcsport_labels.extend([key] * len(loaded_bbcdataset[key]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1fca509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(737, 737)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bbcsport_sentences),len(bbcsport_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5528164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Holmes feted with further honour\\n\\nDouble Olympic champion Kelly Holmes has been voted European Athletics (EAA) woman athlete of 2004 in the governing body's annual poll.\\n\\nThe Briton, made a dame in the New Year Honours List for taking 800m and 1,500m gold, won vital votes from the public, press and EAA member federations. She is only the second British woman to land the title after- Sally Gunnell won for her world 400m hurdles win in 1993. Swedish triple jumper Christian Olsson was voted male athlete of the year. The accolade is the latest in a long list of awards that Holmes has received since her success in Athens. In addition to becoming a dame, she was also named the BBC Sports Personality of the Year in December. Her gutsy victory in the 800m also earned her the International Association of Athletics Federations' award for the best women's performance in the world for 2004. And she scooped two awards at the British Athletics Writers' Association annual dinner in October.\\n\",\n",
       " 'athletics')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbcsport_sentences[1],bbcsport_labels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad54f2d7",
   "metadata": {},
   "source": [
    "## Storing the arrays for later use:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb19c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "## storing the sentences in an array\n",
    "\n",
    "np.save('bbcsport_sentences.npy',np.array(bbcsport_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eea05938",
   "metadata": {},
   "outputs": [],
   "source": [
    "## storing the corresponding labels:\n",
    "\n",
    "np.save('bbcsport_labels.npy',np.array(bbcsport_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "814d47b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WMD_MAX experimentation.ipynb',\n",
       " 'data.json',\n",
       " 'bbcsport_dataset.json',\n",
       " '.ipynb_checkpoints',\n",
       " 'glove.6B.100d.txt',\n",
       " 'wmd.ipynb',\n",
       " 'google300w2v.kv',\n",
       " 'glove.6B.200d.txt',\n",
       " 'model.npy',\n",
       " 'glove.6B.300d.txt',\n",
       " 'bbcsport_sentences.npy',\n",
       " 'glove.6B.zip',\n",
       " 'Miniconda3-latest-Linux-x86_64.sh',\n",
       " 'google300w2v.kv.vectors.npy',\n",
       " 'Untitled.ipynb',\n",
       " 'glove.6B.50d.txt',\n",
       " 'model.npz',\n",
       " 'test_first_jupyteronada.ipynb',\n",
       " 'bbcsport',\n",
       " 'totestsavedmodel.ipynb',\n",
       " 'bbcsport_labels.npy']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "055d6420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " \"Holmes feted with further honour\\n\\nDouble Olympic champion Kelly Holmes has been voted European Athletics (EAA) woman athlete of 2004 in the governing body's annual poll.\\n\\nThe Briton, made a dame in the New Year Honours List for taking 800m and 1,500m gold, won vital votes from the public, press and EAA member federations. She is only the second British woman to land the title after- Sally Gunnell won for her world 400m hurdles win in 1993. Swedish triple jumper Christian Olsson was voted male athlete of the year. The accolade is the latest in a long list of awards that Holmes has received since her success in Athens. In addition to becoming a dame, she was also named the BBC Sports Personality of the Year in December. Her gutsy victory in the 800m also earned her the International Association of Athletics Federations' award for the best women's performance in the world for 2004. And she scooped two awards at the British Athletics Writers' Association annual dinner in October.\\n\",\n",
       " 'athletics')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadedbbcsport_sentences = np.load('bbcsport_sentences.npy')\n",
    "loadedbbcsport_labels = np.load('bbcsport_labels.npy')\n",
    "type(loadedbbcsport_sentences),loadedbbcsport_sentences[1],loadedbbcsport_labels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b1e6c8",
   "metadata": {},
   "source": [
    "## Shuffling the sentences and corresponding labels, then dividing in test train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f970955",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBCsport_sentences_shfld, BBCsport_labels_shfld = sklearn.utils.shuffle(bbcsport_sentences, bbcsport_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d59abb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(737, 737)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(BBCsport_labels_shfld),len(BBCsport_sentences_shfld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "763a117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_BBCsport_sent,Train_BBCsport_label = BBCsport_sentences_shfld[:514], BBCsport_labels_shfld[:514]\n",
    "Test_BBCsport_sent,Test_BBCsport_label = BBCsport_sentences_shfld[515:],BBCsport_labels_shfld[515:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2369cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 36, 52, 31, 71)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_BBCsport_label.count('cricket'),Test_BBCsport_label.count('cricket'),Test_BBCsport_label.count('rugby'),Test_BBCsport_label.count('athletics'),Test_BBCsport_label.count('football')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19a8e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Train_BBCsport_sent.npy',np.array(Train_BBCsport_sent))\n",
    "np.save('Train_BBCsport_label.npy',np.array(Train_BBCsport_label))\n",
    "np.save('Test_BBCsport_sent.npy',np.array(Test_BBCsport_sent))\n",
    "np.save('Test_BBCsport_label.npy',np.array(Test_BBCsport_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28d68531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('football',\n",
       " 'Legendary Dutch boss Michels dies\\n\\nLegendary Dutch coach Rinus Michels, the man credited with developing \"total football\", has died aged 77.\\n\\nReferred to in the Netherlands as \"the General\", Michels led the Dutch at the 1974 World Cup - when they reached the final only to lose 2-1 to Germany. However, he guided his side to the 1988 European Championship title with a 2-0 win over the Soviet Union in the final. Michels played for Ajax and coached the side to four national titles between 1965-71 and a European Cup in 1971. His 1970s Dutch team was built around Johan Cruyff and Johan Neeskens and introduced the concept of \\'total football\\' to the world. The strategy was to foster team coherence and individual imagination - with all players possessing the skills to play in any part of the pitch. Cruyff was the on-field organiser of a team whose players rotated in and out of defence at will and was encouraged to play creative attacking football. Michels had recently undergone heart surgery and Dutch football federation (KNVB) spokesman Frank Huizinga said: \"He was one of the best coaches we had in history.\" The no-nonsense coach also enjoyed spells at Barcelona, who he took to a Spanish title in 1974, FC Cologne and Bayer Leverkusen. Michels, named coach of the century by world football\\'s governing body Fifa in 1999, also won five caps for the Netherlands as a bruising centre forward. Dutch sports minister Clemence Ross-van Dorp said: \"He was the man who, together with Cruyff, made Dutch football big.\"\\n')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BBCsport_labels_shfld[600],BBCsport_sentences_shfld[600]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feae074",
   "metadata": {},
   "source": [
    "## creating an array of words having frequency less than 5 in all the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fed4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdb0b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "945b8011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18370"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allthewords = []\n",
    "\n",
    "for sentence in bbcsport_sentences:\n",
    "    allthewords.extend(sentence.lower().split())\n",
    "    \n",
    "countofwords = Counter(allthewords)   \n",
    "\n",
    "listoflowfrequencywords = [word for word in countofwords.keys() if countofwords[word] < 5]\n",
    "len(listoflowfrequencywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66860d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251456"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allthewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63d22471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wipe',\n",
       " 'hurts',\n",
       " 'worlds.\"',\n",
       " '0.02',\n",
       " '9.87',\n",
       " 'conserving',\n",
       " 'energy.',\n",
       " 'kansas',\n",
       " 'recapturing',\n",
       " 'finland.',\n",
       " 'coming.',\n",
       " 'ato',\n",
       " '(boldon)',\n",
       " '(eaa)',\n",
       " 'dame',\n",
       " 'votes',\n",
       " 'eaa',\n",
       " 'after-',\n",
       " 'sally',\n",
       " 'gunnell',\n",
       " \"federations'\",\n",
       " \"writers'\",\n",
       " 'dougie',\n",
       " 'musselburgh',\n",
       " 'racecourse',\n",
       " 'nandrolone.',\n",
       " 'goon,\"',\n",
       " 'walker.',\n",
       " 'newspaper:',\n",
       " 'shape,',\n",
       " 'chunk',\n",
       " 'half-decent',\n",
       " 'racing.',\n",
       " 'circuit.',\n",
       " 'cagigal',\n",
       " 'memorial',\n",
       " 'kilbride',\n",
       " 'vivancos,',\n",
       " \"haiti's\",\n",
       " 'dudley',\n",
       " '7.64secs',\n",
       " '0.04secs',\n",
       " 'vivancos',\n",
       " 'slashed',\n",
       " '7.60secs',\n",
       " '7.62secs',\n",
       " '7.63secs',\n",
       " 'cooperative',\n",
       " 'illston',\n",
       " 'evidentiary',\n",
       " 'valente,',\n",
       " 'clients',\n",
       " 'bonds,',\n",
       " 'baseball',\n",
       " 'congressional',\n",
       " 'admissibility',\n",
       " 'raids',\n",
       " \"balco's\",\n",
       " 'offices',\n",
       " 'obtain',\n",
       " 'legality',\n",
       " 'raids.',\n",
       " 'confident,\"',\n",
       " 'claxton.',\n",
       " 'translate',\n",
       " 'scotland-born',\n",
       " 'fifth-fastest',\n",
       " 'prix,',\n",
       " 're-focused',\n",
       " 'attentions.',\n",
       " 'etienne.',\n",
       " 'cobh',\n",
       " 'nationals',\n",
       " 'currentily',\n",
       " 'agio.',\n",
       " 'mccambridge',\n",
       " 'fionnualla',\n",
       " 'britton,',\n",
       " 'long-course',\n",
       " 'criminals.',\n",
       " '\"suspicions',\n",
       " 'innuendoes\"',\n",
       " 'greet',\n",
       " '\"doping',\n",
       " 'such,\"',\n",
       " 'promoters,',\n",
       " 'public.\"',\n",
       " 'suspicion',\n",
       " 'penalty,\"',\n",
       " 'detect',\n",
       " 'abused',\n",
       " 'sacrifice',\n",
       " 'trumped',\n",
       " 'route.',\n",
       " '\"often,',\n",
       " 'innuendoes',\n",
       " 'testify',\n",
       " 'kitts',\n",
       " 'nevis',\n",
       " 'venue.\"',\n",
       " 'underestimating',\n",
       " 'evening.\"',\n",
       " 'finland',\n",
       " 'holmes?',\n",
       " 'loneliness,',\n",
       " 'meticulous',\n",
       " 'predict',\n",
       " 'store',\n",
       " 'aspiring',\n",
       " 'spotlight,',\n",
       " 'wilt.',\n",
       " 'know\"',\n",
       " '1500m,',\n",
       " 'distances',\n",
       " 'anymore?',\n",
       " '\"well,',\n",
       " 'everybody,',\n",
       " 'running,\"',\n",
       " 'talented.\"',\n",
       " 'unquestionable',\n",
       " 'empty-handed.',\n",
       " 'bells',\n",
       " 'herself.',\n",
       " '\"will',\n",
       " 'commitment,',\n",
       " 'championship?\"',\n",
       " 'five-time',\n",
       " 'daley',\n",
       " 'grind',\n",
       " '\"doesn\\'t',\n",
       " 'anymore.\"',\n",
       " 'allure',\n",
       " 'indignity',\n",
       " 'fuelled',\n",
       " 'grabs.',\n",
       " 'settled,',\n",
       " 'gnaw',\n",
       " 'realisation',\n",
       " 'trains,',\n",
       " 'celebrated?',\n",
       " 'circuits',\n",
       " 'certain.\"',\n",
       " 'emphatically',\n",
       " 'dragging',\n",
       " 'where,',\n",
       " 'again?',\n",
       " 'kelly,\"',\n",
       " 'pronouncement',\n",
       " \"'you're\",\n",
       " 'decision.\\'\"',\n",
       " 'yelling.',\n",
       " 'keska,',\n",
       " '12km',\n",
       " 'wollaton',\n",
       " 'overwhelmingly',\n",
       " 'dropped.\"',\n",
       " '\"knew\"',\n",
       " 'chicago.',\n",
       " 'then.\"',\n",
       " 'availability.',\n",
       " 'double-olympic',\n",
       " 'punt,',\n",
       " '(distance).',\n",
       " 'permit',\n",
       " 'both.\"',\n",
       " '(at',\n",
       " 'prix).',\n",
       " 'inclined',\n",
       " '(compete).',\n",
       " 'depend',\n",
       " 'chin.',\n",
       " 'pentathlon.',\n",
       " 'newcomers',\n",
       " '46-strong',\n",
       " 'therefore',\n",
       " 'cycle',\n",
       " 'not-so-pressurised',\n",
       " 'step.\"',\n",
       " '60m:',\n",
       " 'chin',\n",
       " '(wessex',\n",
       " 'bath),',\n",
       " '(aldershot,',\n",
       " 'farnham',\n",
       " 'district),',\n",
       " 'baddeley',\n",
       " '(harrow',\n",
       " 'farah',\n",
       " 'mayock',\n",
       " '(barnsley',\n",
       " 'beagles),',\n",
       " '(notts',\n",
       " 'challenger',\n",
       " 'vault:',\n",
       " '(crawley',\n",
       " 'beagles).',\n",
       " 'achike',\n",
       " '(oxford',\n",
       " 'cossins',\n",
       " 'preddy',\n",
       " '(city',\n",
       " 'ladies).',\n",
       " '(basildon',\n",
       " '(preston',\n",
       " '(exeter',\n",
       " 'harriers',\n",
       " 'manchester),',\n",
       " '(herne',\n",
       " '(croydon',\n",
       " '(southampton',\n",
       " '(cas)',\n",
       " 'erroneous.\"',\n",
       " 'refered',\n",
       " 'cas.',\n",
       " 'binding.\"',\n",
       " '\"expected\"',\n",
       " '\"understandable.\"',\n",
       " 'prejudge,\"',\n",
       " 'vassilis',\n",
       " 'sevastis.',\n",
       " 'unexpected\"',\n",
       " 'ioannidis.',\n",
       " 'file',\n",
       " 'proceedings',\n",
       " 'testimonies,',\n",
       " 'speeches',\n",
       " 'counsel...',\n",
       " 'audio',\n",
       " 'tapes.',\n",
       " 'truth.\"',\n",
       " 'closely,\"',\n",
       " 'satisfactorily',\n",
       " 'resolved.\"',\n",
       " 'embu',\n",
       " '10k',\n",
       " 'rico.',\n",
       " 'derartu',\n",
       " 'tokyo',\n",
       " 'marathons,',\n",
       " 'seen,\"',\n",
       " 'tulu\\'s,\"',\n",
       " 'ultra-consistent',\n",
       " 'racer.\"',\n",
       " '2004:',\n",
       " 'invariably',\n",
       " 'unaccountably,',\n",
       " 'olympiad.',\n",
       " 'accurate,',\n",
       " 'watchers.',\n",
       " 'surprised.',\n",
       " 'gillian',\n",
       " 'cathal',\n",
       " 'lombard',\n",
       " 'epo.',\n",
       " \"lombard's\",\n",
       " 'shattering',\n",
       " 'tongues',\n",
       " 'wagging',\n",
       " 'cynical',\n",
       " 'observers,',\n",
       " 'pre-olympic',\n",
       " 'ranch',\n",
       " 'greece,',\n",
       " 'pattern',\n",
       " 'underachievement',\n",
       " \"cragg's\",\n",
       " 'beloved',\n",
       " 'scraped',\n",
       " 'delude',\n",
       " 'believing',\n",
       " 'shake-up.',\n",
       " 'undignified',\n",
       " 'defar.',\n",
       " 'transpired',\n",
       " 'typically,',\n",
       " 'cobhwoman',\n",
       " 'effects',\n",
       " 'amazingly,',\n",
       " 'lite',\n",
       " 'bearer',\n",
       " 'province.',\n",
       " '21.00',\n",
       " 'exit.',\n",
       " 'turnbull,',\n",
       " 'zoe',\n",
       " 'mckee',\n",
       " 'screens.',\n",
       " 'plane.',\n",
       " 'injury-plagued',\n",
       " 'gamely',\n",
       " '3:39',\n",
       " 'achieve,',\n",
       " 'winter.',\n",
       " 'lingering',\n",
       " 'probem',\n",
       " \"mckee's\",\n",
       " 'slice',\n",
       " 'stalwarts',\n",
       " 'catherina',\n",
       " 'spikes.',\n",
       " 'candidly',\n",
       " 'crept',\n",
       " 'injury-ravaged',\n",
       " 'clubman',\n",
       " 'turnout',\n",
       " 'athletics-loving',\n",
       " 'folk',\n",
       " \"andy's\",\n",
       " 'happenings',\n",
       " 'devised',\n",
       " 'nurture',\n",
       " 'contesting',\n",
       " 'coincides',\n",
       " 'updated',\n",
       " 'stimulate',\n",
       " 'athletes,\"',\n",
       " 'identifies',\n",
       " 'strata',\n",
       " 'icon',\n",
       " 'christie.',\n",
       " '\"training',\n",
       " 'broadening',\n",
       " '91kg,',\n",
       " '86.9kg',\n",
       " 'eating',\n",
       " 'foods',\n",
       " 'snacks.',\n",
       " 'running.\"',\n",
       " 'heartbreaking,',\n",
       " 'final.\"',\n",
       " '10,000m,',\n",
       " 'sufficiently',\n",
       " 'record-holder',\n",
       " 'miles.',\n",
       " 'bursts',\n",
       " 'dredge',\n",
       " \"race's\",\n",
       " 'erasing',\n",
       " 'matter-of-fact',\n",
       " '50k',\n",
       " 'walk.',\n",
       " 'ironic',\n",
       " 'chuckle',\n",
       " 'lorry,',\n",
       " 'rental',\n",
       " 'car.',\n",
       " 'guessed',\n",
       " 'broken,\"',\n",
       " 'cortisone',\n",
       " 'know.',\n",
       " 'muscles',\n",
       " 'pelvis',\n",
       " 'laser',\n",
       " 'therapy',\n",
       " 'ultra',\n",
       " 'vertebrae,',\n",
       " 'toe',\n",
       " 'brake.\"',\n",
       " 'killers',\n",
       " \"thinking:'ok,\",\n",
       " 'now\\'.\"',\n",
       " 'ambulance.',\n",
       " \"jamie's\",\n",
       " 'titanium',\n",
       " 'rods',\n",
       " 'vertebrae.',\n",
       " 'fused',\n",
       " 'unaided',\n",
       " '\"walking',\n",
       " 'measurable',\n",
       " 'recovery.\"',\n",
       " 'johnston',\n",
       " 'mcevoy',\n",
       " 'limerick',\n",
       " '\"johnston',\n",
       " 'acupuncture',\n",
       " 'effective.',\n",
       " '\"needles',\n",
       " 'spine.',\n",
       " 'needle',\n",
       " 'yesterday',\n",
       " 'incapacitated',\n",
       " 'spala',\n",
       " 'korzeniowski',\n",
       " 'cryotherapy.',\n",
       " 'cooled',\n",
       " 'liquid',\n",
       " 'nitrogen',\n",
       " 'centigrade',\n",
       " 'promotes',\n",
       " 'healing.\"',\n",
       " 'cryotherapy',\n",
       " 'twice-daily',\n",
       " 'pool-work.',\n",
       " 'mobility',\n",
       " 'muscles.',\n",
       " 'pelvic',\n",
       " 'tightens',\n",
       " 'reacts.',\n",
       " 'spar',\n",
       " 'favourites.',\n",
       " 'sheffield,',\n",
       " \"mcilroy's\",\n",
       " 'transformed',\n",
       " 'sergeant',\n",
       " 'lester.',\n",
       " 'guidance',\n",
       " \"lester's\",\n",
       " 'guidance.',\n",
       " '\"before,',\n",
       " 'everest',\n",
       " '\"trying',\n",
       " 'half-dead',\n",
       " 'cram',\n",
       " 'ovett',\n",
       " '1000m',\n",
       " 'dmitriy',\n",
       " 'bogdanov',\n",
       " 'arnoud',\n",
       " 'okken',\n",
       " 'reina',\n",
       " 'unfazed.',\n",
       " 'opinion.',\n",
       " '46.68seconds',\n",
       " 'interviewed',\n",
       " \"lewis'\",\n",
       " 'connor.',\n",
       " 'person,\"',\n",
       " 'candidates.',\n",
       " 'achieve.\"',\n",
       " 'uk.\"',\n",
       " 'javelin',\n",
       " 'thrower',\n",
       " 'backley',\n",
       " 'marine',\n",
       " 'pe',\n",
       " 'teacher.',\n",
       " 'professor',\n",
       " 'university,',\n",
       " 'sports,',\n",
       " 'specialised',\n",
       " 'psychology',\n",
       " 'karate.',\n",
       " 'arrives',\n",
       " 'crossroads.',\n",
       " 'careers,',\n",
       " \"foster's\",\n",
       " 'justify',\n",
       " \"connor's\",\n",
       " 'arduous',\n",
       " 'foster,',\n",
       " 'recruitment',\n",
       " 'pre-race',\n",
       " 'inspiring',\n",
       " 'baton',\n",
       " 'americans.',\n",
       " 'coby',\n",
       " '300m',\n",
       " 'bend.',\n",
       " 'cue,',\n",
       " 'textbook',\n",
       " 'hundredth',\n",
       " 'harrier.',\n",
       " 'friends,',\n",
       " 'dreamed',\n",
       " 'sprinter.',\n",
       " 'journey,\"',\n",
       " 'obe.',\n",
       " 'zara',\n",
       " 'peters',\n",
       " 'nominations.',\n",
       " 'messing',\n",
       " 'brussels.',\n",
       " 'explanations.',\n",
       " 'grigoris',\n",
       " 'ioanidis',\n",
       " 'innocent.',\n",
       " 'dropped,\"',\n",
       " 'ioanidis.',\n",
       " '[a',\n",
       " 'case]',\n",
       " 'unreasonable.\"',\n",
       " 'village.',\n",
       " \"thanou's\",\n",
       " '[by',\n",
       " 'committee]',\n",
       " 'kinds',\n",
       " 'august,\"',\n",
       " 'gaps.',\n",
       " '[of',\n",
       " 'tested],',\n",
       " 'optimistic.\"',\n",
       " '\"deliberations',\n",
       " 'documents',\n",
       " 'thursday,\"',\n",
       " 'panagopoulos.',\n",
       " 'estimate',\n",
       " 'isinbayeva.',\n",
       " 'birmingham.\"',\n",
       " 'rival,',\n",
       " 'feofanova,',\n",
       " '4.91m',\n",
       " 'isinbayeva,',\n",
       " 'vault,',\n",
       " 'faked',\n",
       " 'motorbike',\n",
       " 'insisted:',\n",
       " 'supposedly',\n",
       " 'village.\"',\n",
       " \"greece's\",\n",
       " 'alter',\n",
       " 'station,',\n",
       " 'olympics-accredited',\n",
       " 'came.\"',\n",
       " 'withdrew.',\n",
       " 'gladly.',\n",
       " 'prosecution',\n",
       " 'cleared...',\n",
       " \"who's\",\n",
       " 'isn\\'t.\"',\n",
       " 'flame',\n",
       " 'rehearsed',\n",
       " 'cauldron,\"',\n",
       " \"again'\",\n",
       " 'vassilli',\n",
       " 'parliament:',\n",
       " 'reponse',\n",
       " 'spearate',\n",
       " 'parliament',\n",
       " 'snake',\n",
       " 'hole',\n",
       " 'athletes?\"',\n",
       " 'reviews',\n",
       " 'reversed.\"',\n",
       " 'laboratories.',\n",
       " 'innocent,',\n",
       " 'speculate',\n",
       " 'emerge\".',\n",
       " 'hinge',\n",
       " 'stating',\n",
       " 'closing.',\n",
       " 'attorney',\n",
       " 'nichols,',\n",
       " '\"conte',\n",
       " 'indictment',\n",
       " 'contradictory,',\n",
       " 'statements.\"',\n",
       " \"joyner-kersee's\",\n",
       " '7291',\n",
       " 'surpassed.',\n",
       " '7001',\n",
       " 'unbeatable,\"',\n",
       " 'joyner-kersee',\n",
       " 'larisa',\n",
       " 'nikitina',\n",
       " '7000',\n",
       " 'collection,',\n",
       " 'anniversary,\"',\n",
       " 'ever.\"',\n",
       " 'bedford',\n",
       " 'lowering',\n",
       " 'mixed-race',\n",
       " '2:17:18,',\n",
       " '\"big',\n",
       " 'city\"',\n",
       " 'conquered',\n",
       " '\"boston',\n",
       " 'atmosphere,',\n",
       " 'moroccan,',\n",
       " 'records.',\n",
       " 'courses.',\n",
       " 'galmier',\n",
       " 'assesses',\n",
       " 'invitations',\n",
       " 'guerrouj.',\n",
       " 'sotherton,',\n",
       " '6.43m',\n",
       " 'fouls.',\n",
       " \"sotherton's\",\n",
       " '21.01',\n",
       " '20.94',\n",
       " 'allyn',\n",
       " 'condon',\n",
       " 'heats.',\n",
       " 'turner.',\n",
       " '7.58',\n",
       " '7.82',\n",
       " '7.83',\n",
       " '9:05.00',\n",
       " '9:05.73.',\n",
       " 'heats,',\n",
       " 'rankings,',\n",
       " '1:50.87',\n",
       " 'thunder',\n",
       " '23.68',\n",
       " 'distance,',\n",
       " '23.67.',\n",
       " '15.27m.',\n",
       " '39-year-old',\n",
       " '13.77m.',\n",
       " 'myerscough,',\n",
       " '17.64m,',\n",
       " '2.20m',\n",
       " '3cm',\n",
       " '2.16m',\n",
       " \"27-year-old's\",\n",
       " 'tempered',\n",
       " '5.45m.',\n",
       " 'swain,',\n",
       " '5.25m',\n",
       " 'taniesha',\n",
       " 'scanlon',\n",
       " '13.28m',\n",
       " 'bute',\n",
       " 'part-time',\n",
       " 'teacher',\n",
       " 'six-kilometre',\n",
       " 'damen,',\n",
       " '9km',\n",
       " 'kilometres',\n",
       " 'glynn',\n",
       " 'tromans',\n",
       " 'inter-countries',\n",
       " 'lay-off.',\n",
       " 'rolling',\n",
       " 'bests.',\n",
       " 'gardener.',\n",
       " 'news,',\n",
       " 'pognon,',\n",
       " '6.45,',\n",
       " 'one-hundreth',\n",
       " '\"you\\'ll',\n",
       " 'along,\"',\n",
       " 'katherine',\n",
       " 'allahgreen.',\n",
       " 'happy,\"',\n",
       " 'tearful',\n",
       " 'recognition.\"',\n",
       " 'startling',\n",
       " '47.96',\n",
       " 'mcilory',\n",
       " 'watkins,',\n",
       " '1:48.32,',\n",
       " '2:04.45.',\n",
       " '1.80m',\n",
       " '8.47secs',\n",
       " 'sotherton.',\n",
       " 'steroids,',\n",
       " '4.25m.',\n",
       " '26-year-old,',\n",
       " 'clue,\"',\n",
       " 'idowu.',\n",
       " 'steady',\n",
       " '16.76m',\n",
       " '7.96m',\n",
       " 'heel.',\n",
       " '7.91m.',\n",
       " 'mark,\"',\n",
       " 'tomlinson.',\n",
       " 'steal',\n",
       " '53.45',\n",
       " \"wall's\",\n",
       " '46.46',\n",
       " 'garland.',\n",
       " 'sudanese',\n",
       " 'citizenship,',\n",
       " '1.90m',\n",
       " '56.86',\n",
       " 'eight-minute',\n",
       " '4:19.11',\n",
       " 'ovens',\n",
       " '3:45.87.',\n",
       " 'francisco.',\n",
       " 'wrongfully',\n",
       " \"company's\",\n",
       " 'valente.',\n",
       " 'innocence.',\n",
       " 'drugs,\"',\n",
       " 'cooperative)',\n",
       " 'sanctions',\n",
       " 'avenge',\n",
       " 'anchor',\n",
       " 'performance.\"',\n",
       " 'holder,',\n",
       " 'eliud',\n",
       " '9.2km',\n",
       " 'kenyan,',\n",
       " 'gebre',\n",
       " 'gebremariam',\n",
       " 'dejene',\n",
       " 'berhanu',\n",
       " 'morpeth',\n",
       " 'skinner',\n",
       " \"baddeley's\",\n",
       " 'lasp',\n",
       " 'lap.',\n",
       " 'asi',\n",
       " 'shape,\"',\n",
       " '6.2km',\n",
       " 'britons',\n",
       " 'shakes',\n",
       " 'cramp',\n",
       " 'replicate',\n",
       " 'maurice,\"',\n",
       " 'panagopoulos,',\n",
       " 'substantiated,\"',\n",
       " '(kenteris)',\n",
       " 'thanou.\"',\n",
       " 'exonerated',\n",
       " 'harmful',\n",
       " 'substantiated',\n",
       " 'deliberations',\n",
       " 'stain',\n",
       " 'pressures.\"',\n",
       " 'joanna',\n",
       " 'awards,',\n",
       " \"field's\",\n",
       " '(usatf)',\n",
       " 'honour.',\n",
       " '9.85',\n",
       " 'relay,',\n",
       " '12.37',\n",
       " '1981,',\n",
       " '1936',\n",
       " 'annually',\n",
       " 'conjunction',\n",
       " 'usatf',\n",
       " 'portland.',\n",
       " 'award,\"',\n",
       " 'gatlin.',\n",
       " '\"knowing',\n",
       " 'represents,',\n",
       " 'accomplishment',\n",
       " \"'must\",\n",
       " \"guilty'\",\n",
       " 'laboratories,',\n",
       " 'pound.',\n",
       " 'taken,',\n",
       " 'laboratories',\n",
       " 'wide-reaching',\n",
       " 'people.\"',\n",
       " 'fiance',\n",
       " 'rawlinson.',\n",
       " 'courted,\"',\n",
       " \"rawlinson's\",\n",
       " \"dakin's\",\n",
       " 'iwan',\n",
       " 'kemel',\n",
       " 'permanent.',\n",
       " 'chris,\"',\n",
       " 'easter,',\n",
       " 'hurdle.',\n",
       " 'upset.',\n",
       " \"couple's\",\n",
       " 'both,\"',\n",
       " 'dakin.',\n",
       " 'pitfalls.',\n",
       " 'commonwealths',\n",
       " 'finalised',\n",
       " 'rawlison',\n",
       " 'reversed',\n",
       " 'apology.',\n",
       " 'withdrawn',\n",
       " 'absence,\"',\n",
       " 'rice',\n",
       " 'apology.\"',\n",
       " '32-strong',\n",
       " 'end,\"',\n",
       " '\"subject',\n",
       " \"doctor's\",\n",
       " 'confirmation,',\n",
       " 'masai,\"',\n",
       " 'teag',\n",
       " 'erfurt.',\n",
       " '46.68',\n",
       " 'most,\"',\n",
       " '28-year-old.',\n",
       " 'simms',\n",
       " 'brimming',\n",
       " 'corner.\"',\n",
       " 'accelerated',\n",
       " '300m,',\n",
       " 'wolfram',\n",
       " 'mulle',\n",
       " '0.90',\n",
       " 'world-leading',\n",
       " 'sparkassen',\n",
       " 'patterns',\n",
       " 'harsh,\"',\n",
       " 'reconsider.\"',\n",
       " '£25,000',\n",
       " 'track,',\n",
       " '£100,000',\n",
       " '(uka)',\n",
       " 'prioritise',\n",
       " 'birmingham,\"',\n",
       " 'sheffield.\"',\n",
       " 'earnings.',\n",
       " '\"during',\n",
       " 'talks,',\n",
       " 'trials.\"',\n",
       " 'criteria,',\n",
       " '\"exceptional',\n",
       " 'circumstances\".',\n",
       " 'dozen',\n",
       " 'prospects.',\n",
       " 'sub-eight',\n",
       " 'goods',\n",
       " 'counted.',\n",
       " 'sarah.',\n",
       " 'hurdlers',\n",
       " 'lit',\n",
       " 'events,',\n",
       " '17.30m,',\n",
       " 'runway',\n",
       " 'helpful,',\n",
       " 'developing.',\n",
       " 'complicated',\n",
       " 'chatted',\n",
       " 'kwayke',\n",
       " 'maduaka.',\n",
       " 'quicker.',\n",
       " 'topics',\n",
       " 'yusuf.',\n",
       " 'londoner',\n",
       " 'trinidad',\n",
       " 'tobago',\n",
       " 'citizenship.',\n",
       " 'toe,',\n",
       " 'individually,',\n",
       " 'victorious',\n",
       " 'helsinki,',\n",
       " 'findings.',\n",
       " 'proved,',\n",
       " 'epo,',\n",
       " 'testosterone/epitestosterone',\n",
       " 'thg,\"',\n",
       " '\"collins',\n",
       " 'violations',\n",
       " 'usada.',\n",
       " 'csa',\n",
       " 'enforcement',\n",
       " 'madden',\n",
       " \"panel's\",\n",
       " 'violate',\n",
       " 'drug-free,\"',\n",
       " 'madden.',\n",
       " 'laundering',\n",
       " '6.56',\n",
       " 'marc',\n",
       " 'blume,',\n",
       " '6.67',\n",
       " 'vomiting.',\n",
       " 'perfectly.\"',\n",
       " 'tank',\n",
       " '21.72',\n",
       " 'kosenkow',\n",
       " '21.07',\n",
       " 'secs',\n",
       " 'balkom',\n",
       " '21.58',\n",
       " 'norway.',\n",
       " '16.50m',\n",
       " 'ghent.',\n",
       " '37cm',\n",
       " 'jadel',\n",
       " \"gregorio's\",\n",
       " 'christine',\n",
       " 'arron',\n",
       " 'gevaert',\n",
       " '7.35.',\n",
       " 'low-key',\n",
       " '1.76m',\n",
       " '13.86m',\n",
       " 'put.',\n",
       " 'offices.',\n",
       " 'yiannis',\n",
       " 'papadoyiannakis,',\n",
       " 'testified',\n",
       " 'uphold',\n",
       " 'institution,\"',\n",
       " 'papadoyiannakis.',\n",
       " '\"whatever',\n",
       " 'moments.\"',\n",
       " 'five-member',\n",
       " 'examining',\n",
       " 'prohibited',\n",
       " 'tampering',\n",
       " 'prosecutor',\n",
       " 'doping-related',\n",
       " 'illogical,\"',\n",
       " 'tussle',\n",
       " '\"susan',\n",
       " 'chepkemei,',\n",
       " 'kilometre',\n",
       " 'apple',\n",
       " 'outsprinted',\n",
       " 'tyneside',\n",
       " 'border.',\n",
       " 'recently-crowned',\n",
       " 'sportsweek:',\n",
       " 'hunger',\n",
       " '100m)',\n",
       " '200m).\"',\n",
       " '31-year-old,',\n",
       " '(individual)',\n",
       " 'medals.',\n",
       " 'different?',\n",
       " 'olympics.\"',\n",
       " '10.04secs',\n",
       " 'budapest',\n",
       " '20.13secs',\n",
       " 'silver.',\n",
       " 'sun-herald.',\n",
       " 'freeman,',\n",
       " 'individual.',\n",
       " 'competitiveness',\n",
       " 'instinct,',\n",
       " 'channelled',\n",
       " 'raelene',\n",
       " 'wisdom',\n",
       " 'retire,',\n",
       " 'relay.\"',\n",
       " 'dope',\n",
       " \"pound's\",\n",
       " '\"comments',\n",
       " 'embarrass',\n",
       " 'bodies,',\n",
       " 'hostage',\n",
       " 'further,\"',\n",
       " 'separately',\n",
       " \"february's\",\n",
       " 'mentor',\n",
       " 'bekele.',\n",
       " 'targets.\"',\n",
       " \"gebrselassie's\",\n",
       " '04.69',\n",
       " 'stranger',\n",
       " 'overhauling',\n",
       " 'mulugeta',\n",
       " 'wondimu,',\n",
       " 'abiyote',\n",
       " 'abate',\n",
       " 'geneti,',\n",
       " '3000m,',\n",
       " '1000m.',\n",
       " 'soar',\n",
       " 'goodbye',\n",
       " 'obviously,',\n",
       " 'differing',\n",
       " 'formality.',\n",
       " 'i,',\n",
       " 'i?\"',\n",
       " 'story.',\n",
       " 'stake.',\n",
       " 'commentating,',\n",
       " 'stairs,',\n",
       " 'hug.',\n",
       " 'loves',\n",
       " 'bannister',\n",
       " 'with,',\n",
       " 'misunderstood.',\n",
       " 'wise.',\n",
       " 'reacting.',\n",
       " 'drained.',\n",
       " 'smallest',\n",
       " 'brick',\n",
       " 'thrilling.',\n",
       " 'nip-and-tuck',\n",
       " 'marathons.',\n",
       " 'words,',\n",
       " '\"bouncebackability\".',\n",
       " 'inkling',\n",
       " 'pan',\n",
       " 'papered',\n",
       " 'cracks',\n",
       " 'breed?',\n",
       " 'gloomier',\n",
       " 'finisher',\n",
       " 'beyond.',\n",
       " 'paula,',\n",
       " 'preserve.',\n",
       " 'scandals,',\n",
       " 'balco.',\n",
       " 'blind',\n",
       " 'stops',\n",
       " 'costas',\n",
       " 'mid-march,\"',\n",
       " 'lawyers,',\n",
       " 'michalis',\n",
       " 'dimitrakopoulos.',\n",
       " 'spectacularly',\n",
       " 'segas,',\n",
       " 'acquitted.',\n",
       " 'almeria',\n",
       " 'tendon.',\n",
       " 'coup',\n",
       " \"haile's\",\n",
       " 'stefano',\n",
       " 'baldini,',\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listoflowfrequencywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef52cd9",
   "metadata": {},
   "source": [
    "## NOW KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fd0fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_Category(sentence):\n",
    "    \n",
    "    for category in categories\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
